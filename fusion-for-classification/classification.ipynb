{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X4EESwEmebvV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the dictionary mapping shape names to numerical labels\n",
        "shape2number = {'circle': 0, 'square': 1, 'triangle': 2, 'pentagon': 3}\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_path = 'Imagefusion_Dataset'\n",
        "\n",
        "# Define transformations for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to 32x32\n",
        "    transforms.ToTensor()  # Convert to tensor\n",
        "])\n",
        "\n",
        "class SingleImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = sorted(os.listdir(img_dir))\n",
        "        self.labels = [self.load_label(os.path.join(label_dir, f\"{os.path.splitext(img)[0]}.txt\")) for img in self.image_files]\n",
        "\n",
        "    def load_label(self, label_path):\n",
        "        with open(label_path, 'r') as file:\n",
        "            label = file.readline().strip()\n",
        "        return shape2number[label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.image_files[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Create datasets for each image folder\n",
        "label_dir = os.path.join(dataset_path, 'label')  # Assuming the labels folder is named 'labels'\n",
        "img1_dataset = SingleImageDataset(os.path.join(dataset_path, 'img', 'img1'), label_dir, transform)\n",
        "img2_dataset = SingleImageDataset(os.path.join(dataset_path, 'img', 'img2'), label_dir, transform)\n",
        "img3_dataset = SingleImageDataset(os.path.join(dataset_path, 'img', 'img3'), label_dir, transform)\n",
        "\n",
        "# Split datasets into training and testing sets\n",
        "def split_dataset(dataset):\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    return random_split(dataset, [train_size, test_size])\n",
        "\n",
        "img1_train, img1_test = split_dataset(img1_dataset)\n",
        "img2_train, img2_test = split_dataset(img2_dataset)\n",
        "img3_train, img3_test = split_dataset(img3_dataset)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 40\n",
        "img1_train_loader = DataLoader(img1_train, batch_size=batch_size, shuffle=True)\n",
        "img1_test_loader = DataLoader(img1_test, batch_size=batch_size, shuffle=False)\n",
        "img2_train_loader = DataLoader(img2_train, batch_size=batch_size, shuffle=True)\n",
        "img2_test_loader = DataLoader(img2_test, batch_size=batch_size, shuffle=False)\n",
        "img3_train_loader = DataLoader(img3_train, batch_size=batch_size, shuffle=True)\n",
        "img3_test_loader = DataLoader(img3_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=2)  # 3 input channels for RGB images\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
        "        self.fc1 = nn.Linear(16*6*6, 120)  # Adjusted input size to 16*8*8\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*6*6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XG-pB6Ndeuhs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and evaluating on img1:\n",
            "Epoch 1/100, Loss: 1.3834166884422303\n",
            "Epoch 2/100, Loss: 1.3653368830680848\n",
            "Epoch 3/100, Loss: 1.3418354570865632\n",
            "Epoch 4/100, Loss: 1.2566810965538024\n",
            "Epoch 5/100, Loss: 1.1716988325119018\n",
            "Epoch 6/100, Loss: 1.1706124663352966\n",
            "Epoch 7/100, Loss: 1.1000100672245026\n",
            "Epoch 8/100, Loss: 1.042282611131668\n",
            "Epoch 9/100, Loss: 1.0385566979646683\n",
            "Epoch 10/100, Loss: 0.987696397304535\n",
            "Epoch 11/100, Loss: 0.9368215650320053\n",
            "Epoch 12/100, Loss: 0.9364133775234222\n",
            "Epoch 13/100, Loss: 0.8932770371437073\n",
            "Epoch 14/100, Loss: 0.8799770057201386\n",
            "Epoch 15/100, Loss: 0.8444756209850312\n",
            "Epoch 16/100, Loss: 0.8456706255674362\n",
            "Epoch 17/100, Loss: 0.8386605650186538\n",
            "Epoch 18/100, Loss: 0.8197568237781525\n",
            "Epoch 19/100, Loss: 0.8209322601556778\n",
            "Epoch 20/100, Loss: 0.7840207040309906\n",
            "Epoch 21/100, Loss: 0.7691056370735169\n",
            "Epoch 22/100, Loss: 0.7455288112163544\n",
            "Epoch 23/100, Loss: 0.7430459678173065\n",
            "Epoch 24/100, Loss: 0.7895086735486985\n",
            "Epoch 25/100, Loss: 0.7404975950717926\n",
            "Epoch 26/100, Loss: 0.7196237325668335\n",
            "Epoch 27/100, Loss: 0.710436874628067\n",
            "Epoch 28/100, Loss: 0.6773710787296295\n",
            "Epoch 29/100, Loss: 0.6750046014785767\n",
            "Epoch 30/100, Loss: 0.6821774244308472\n",
            "Epoch 31/100, Loss: 0.6694149017333985\n",
            "Epoch 32/100, Loss: 0.6583461076021194\n",
            "Epoch 33/100, Loss: 0.6469821006059646\n",
            "Epoch 34/100, Loss: 0.6232429772615433\n",
            "Epoch 35/100, Loss: 0.5959792450070381\n",
            "Epoch 36/100, Loss: 0.5959705889225007\n",
            "Epoch 37/100, Loss: 0.5782645136117935\n",
            "Epoch 38/100, Loss: 0.571053646504879\n",
            "Epoch 39/100, Loss: 0.5263438656926155\n",
            "Epoch 40/100, Loss: 0.5132784724235535\n",
            "Epoch 41/100, Loss: 0.5106577262282371\n",
            "Epoch 42/100, Loss: 0.5129155099391938\n",
            "Epoch 43/100, Loss: 0.47891855984926224\n",
            "Epoch 44/100, Loss: 0.48290426582098006\n",
            "Epoch 45/100, Loss: 0.47102454751729966\n",
            "Epoch 46/100, Loss: 0.45514747351408\n",
            "Epoch 47/100, Loss: 0.4602745518088341\n",
            "Epoch 48/100, Loss: 0.4356679439544678\n",
            "Epoch 49/100, Loss: 0.4333909496665001\n",
            "Epoch 50/100, Loss: 0.41373717337846755\n",
            "Epoch 51/100, Loss: 0.4273195847868919\n",
            "Epoch 52/100, Loss: 0.4290890634059906\n",
            "Epoch 53/100, Loss: 0.4086638048291206\n",
            "Epoch 54/100, Loss: 0.3741591066122055\n",
            "Epoch 55/100, Loss: 0.3603110000491142\n",
            "Epoch 56/100, Loss: 0.3437057569622993\n",
            "Epoch 57/100, Loss: 0.38894744142889975\n",
            "Epoch 58/100, Loss: 0.39424812123179437\n",
            "Epoch 59/100, Loss: 0.3557641312479973\n",
            "Epoch 60/100, Loss: 0.31204310730099677\n",
            "Epoch 61/100, Loss: 0.30638175308704374\n",
            "Epoch 62/100, Loss: 0.30011299923062323\n",
            "Epoch 63/100, Loss: 0.30756689980626106\n",
            "Epoch 64/100, Loss: 0.28899910375475885\n",
            "Epoch 65/100, Loss: 0.2743809729814529\n",
            "Epoch 66/100, Loss: 0.2683435633778572\n",
            "Epoch 67/100, Loss: 0.25380572974681853\n",
            "Epoch 68/100, Loss: 0.2589213725179434\n",
            "Epoch 69/100, Loss: 0.22220831364393234\n",
            "Epoch 70/100, Loss: 0.21399461925029756\n",
            "Epoch 71/100, Loss: 0.20589976273477079\n",
            "Epoch 72/100, Loss: 0.1750500787049532\n",
            "Epoch 73/100, Loss: 0.17546992860734462\n",
            "Epoch 74/100, Loss: 0.16251540072262288\n",
            "Epoch 75/100, Loss: 0.16163633354008197\n",
            "Epoch 76/100, Loss: 0.14454294480383395\n",
            "Epoch 77/100, Loss: 0.1524016870185733\n",
            "Epoch 78/100, Loss: 0.14652765728533268\n",
            "Epoch 79/100, Loss: 0.12295809350907802\n",
            "Epoch 80/100, Loss: 0.11959688179194927\n",
            "Epoch 81/100, Loss: 0.12555840220302344\n",
            "Epoch 82/100, Loss: 0.1350143153220415\n",
            "Epoch 83/100, Loss: 0.10278909411281348\n",
            "Epoch 84/100, Loss: 0.07014166694134474\n",
            "Epoch 85/100, Loss: 0.07437406815588474\n",
            "Epoch 86/100, Loss: 0.07614550292491913\n",
            "Epoch 87/100, Loss: 0.07815843066200615\n",
            "Epoch 88/100, Loss: 0.11045451387763024\n",
            "Epoch 89/100, Loss: 0.05948005001991987\n",
            "Epoch 90/100, Loss: 0.04217026680707932\n",
            "Epoch 91/100, Loss: 0.04019519677385688\n",
            "Epoch 92/100, Loss: 0.03315538680180907\n",
            "Epoch 93/100, Loss: 0.03562399263028056\n",
            "Epoch 94/100, Loss: 0.03781107868999243\n",
            "Epoch 95/100, Loss: 0.03238661019131541\n",
            "Epoch 96/100, Loss: 0.026848234701901674\n",
            "Epoch 97/100, Loss: 0.019513726281002165\n",
            "Epoch 98/100, Loss: 0.019780305819585918\n",
            "Epoch 99/100, Loss: 0.037007096060551706\n",
            "Epoch 100/100, Loss: 0.04647515648975968\n",
            "Accuracy on img1: 78.0\n",
            "Training and evaluating on img2:\n",
            "Epoch 1/100, Loss: 1.37632777094841\n",
            "Epoch 2/100, Loss: 1.3507201015949248\n",
            "Epoch 3/100, Loss: 1.2894503772258759\n",
            "Epoch 4/100, Loss: 1.1834320306777955\n",
            "Epoch 5/100, Loss: 1.1454132437705993\n",
            "Epoch 6/100, Loss: 1.11422860622406\n",
            "Epoch 7/100, Loss: 1.0950319021940231\n",
            "Epoch 8/100, Loss: 1.04316845536232\n",
            "Epoch 9/100, Loss: 1.0216872215270996\n",
            "Epoch 10/100, Loss: 1.0911219269037247\n",
            "Epoch 11/100, Loss: 1.0108309864997864\n",
            "Epoch 12/100, Loss: 1.0122410207986832\n",
            "Epoch 13/100, Loss: 0.9796235978603363\n",
            "Epoch 14/100, Loss: 0.9489856421947479\n",
            "Epoch 15/100, Loss: 0.9230232626199723\n",
            "Epoch 16/100, Loss: 1.010878711938858\n",
            "Epoch 17/100, Loss: 0.9401504665613174\n",
            "Epoch 18/100, Loss: 0.9649759799242019\n",
            "Epoch 19/100, Loss: 0.9308667689561844\n",
            "Epoch 20/100, Loss: 0.8610286384820938\n",
            "Epoch 21/100, Loss: 0.8565038561820983\n",
            "Epoch 22/100, Loss: 0.8183351397514343\n",
            "Epoch 23/100, Loss: 0.8035995572805404\n",
            "Epoch 24/100, Loss: 0.825726592540741\n",
            "Epoch 25/100, Loss: 0.829209715127945\n",
            "Epoch 26/100, Loss: 0.7968440264463424\n",
            "Epoch 27/100, Loss: 0.78581463098526\n",
            "Epoch 28/100, Loss: 0.8887277841567993\n",
            "Epoch 29/100, Loss: 0.8436945974826813\n",
            "Epoch 30/100, Loss: 0.7927489072084427\n",
            "Epoch 31/100, Loss: 0.7670273005962371\n",
            "Epoch 32/100, Loss: 0.7675685524940491\n",
            "Epoch 33/100, Loss: 0.7836792737245559\n",
            "Epoch 34/100, Loss: 0.7743140697479248\n",
            "Epoch 35/100, Loss: 0.7360098451375962\n",
            "Epoch 36/100, Loss: 0.7403004348278046\n",
            "Epoch 37/100, Loss: 0.7582558959722518\n",
            "Epoch 38/100, Loss: 0.7181884527206421\n",
            "Epoch 39/100, Loss: 0.7094906777143478\n",
            "Epoch 40/100, Loss: 0.7141137182712555\n",
            "Epoch 41/100, Loss: 0.6885865747928619\n",
            "Epoch 42/100, Loss: 0.6626544326543808\n",
            "Epoch 43/100, Loss: 0.6677341043949128\n",
            "Epoch 44/100, Loss: 0.6691369131207466\n",
            "Epoch 45/100, Loss: 0.6596456348896027\n",
            "Epoch 46/100, Loss: 0.6423245340585708\n",
            "Epoch 47/100, Loss: 0.6286621332168579\n",
            "Epoch 48/100, Loss: 0.6206521660089492\n",
            "Epoch 49/100, Loss: 0.6148854270577431\n",
            "Epoch 50/100, Loss: 0.6842677757143975\n",
            "Epoch 51/100, Loss: 0.660493616759777\n",
            "Epoch 52/100, Loss: 0.6287976384162903\n",
            "Epoch 53/100, Loss: 0.5727672025561332\n",
            "Epoch 54/100, Loss: 0.5700880751013756\n",
            "Epoch 55/100, Loss: 0.5868491813540458\n",
            "Epoch 56/100, Loss: 0.5676801294088364\n",
            "Epoch 57/100, Loss: 0.563034687936306\n",
            "Epoch 58/100, Loss: 0.6113142460584641\n",
            "Epoch 59/100, Loss: 0.5846720233559608\n",
            "Epoch 60/100, Loss: 0.5317978844046592\n",
            "Epoch 61/100, Loss: 0.5399376854300499\n",
            "Epoch 62/100, Loss: 0.5211220502853393\n",
            "Epoch 63/100, Loss: 0.5090389907360077\n",
            "Epoch 64/100, Loss: 0.4887047722935677\n",
            "Epoch 65/100, Loss: 0.5199670851230621\n",
            "Epoch 66/100, Loss: 0.5060068562626838\n",
            "Epoch 67/100, Loss: 0.4620657995343208\n",
            "Epoch 68/100, Loss: 0.4762764275074005\n",
            "Epoch 69/100, Loss: 0.468419174849987\n",
            "Epoch 70/100, Loss: 0.44686524420976637\n",
            "Epoch 71/100, Loss: 0.44644955098628997\n",
            "Epoch 72/100, Loss: 0.45122414380311965\n",
            "Epoch 73/100, Loss: 0.4309714466333389\n",
            "Epoch 74/100, Loss: 0.41991748064756396\n",
            "Epoch 75/100, Loss: 0.4674495071172714\n",
            "Epoch 76/100, Loss: 0.422904497385025\n",
            "Epoch 77/100, Loss: 0.4235088124871254\n",
            "Epoch 78/100, Loss: 0.40014652609825135\n",
            "Epoch 79/100, Loss: 0.40645106583833696\n",
            "Epoch 80/100, Loss: 0.3938827902078629\n",
            "Epoch 81/100, Loss: 0.3855717107653618\n",
            "Epoch 82/100, Loss: 0.39691640585660937\n",
            "Epoch 83/100, Loss: 0.3609007328748703\n",
            "Epoch 84/100, Loss: 0.3453755810856819\n",
            "Epoch 85/100, Loss: 0.33648397475481034\n",
            "Epoch 86/100, Loss: 0.4161109209060669\n",
            "Epoch 87/100, Loss: 0.3714571475982666\n",
            "Epoch 88/100, Loss: 0.37767041474580765\n",
            "Epoch 89/100, Loss: 0.34869539737701416\n",
            "Epoch 90/100, Loss: 0.32169587463140487\n",
            "Epoch 91/100, Loss: 0.3141610771417618\n",
            "Epoch 92/100, Loss: 0.31356011927127836\n",
            "Epoch 93/100, Loss: 0.3125142723321915\n",
            "Epoch 94/100, Loss: 0.34597005397081376\n",
            "Epoch 95/100, Loss: 0.3152249090373516\n",
            "Epoch 96/100, Loss: 0.33729107305407524\n",
            "Epoch 97/100, Loss: 0.28963432312011717\n",
            "Epoch 98/100, Loss: 0.30630325600504876\n",
            "Epoch 99/100, Loss: 0.31544548124074934\n",
            "Epoch 100/100, Loss: 0.3079691156744957\n",
            "Accuracy on img2: 76.0\n",
            "Training and evaluating on img3:\n",
            "Epoch 1/100, Loss: 1.3542351961135863\n",
            "Epoch 2/100, Loss: 1.2271708309650422\n",
            "Epoch 3/100, Loss: 1.0842555433511734\n",
            "Epoch 4/100, Loss: 1.0285234332084656\n",
            "Epoch 5/100, Loss: 1.0472336530685424\n",
            "Epoch 6/100, Loss: 1.047686442732811\n",
            "Epoch 7/100, Loss: 0.9807873338460922\n",
            "Epoch 8/100, Loss: 0.9788216352462769\n",
            "Epoch 9/100, Loss: 0.9837868124246597\n",
            "Epoch 10/100, Loss: 0.9508089751005173\n",
            "Epoch 11/100, Loss: 0.9577399432659149\n",
            "Epoch 12/100, Loss: 0.9656709849834442\n",
            "Epoch 13/100, Loss: 0.9132469803094864\n",
            "Epoch 14/100, Loss: 0.9144507259130478\n",
            "Epoch 15/100, Loss: 0.9358857721090317\n",
            "Epoch 16/100, Loss: 0.8997362226247787\n",
            "Epoch 17/100, Loss: 0.875017273426056\n",
            "Epoch 18/100, Loss: 0.8548003524541855\n",
            "Epoch 19/100, Loss: 0.8565088361501694\n",
            "Epoch 20/100, Loss: 0.8178482323884964\n",
            "Epoch 21/100, Loss: 0.8566450566053391\n",
            "Epoch 22/100, Loss: 0.8451690077781677\n",
            "Epoch 23/100, Loss: 0.8171146631240844\n",
            "Epoch 24/100, Loss: 0.8180531114339828\n",
            "Epoch 25/100, Loss: 0.8074770987033844\n",
            "Epoch 26/100, Loss: 0.7669210076332093\n",
            "Epoch 27/100, Loss: 0.7652068734169006\n",
            "Epoch 28/100, Loss: 0.7505011975765228\n",
            "Epoch 29/100, Loss: 0.7614033848047257\n",
            "Epoch 30/100, Loss: 0.7658424437046051\n",
            "Epoch 31/100, Loss: 0.7946178436279296\n",
            "Epoch 32/100, Loss: 0.7677813947200776\n",
            "Epoch 33/100, Loss: 0.7154643386602402\n",
            "Epoch 34/100, Loss: 0.7228148341178894\n",
            "Epoch 35/100, Loss: 0.7455494046211243\n",
            "Epoch 36/100, Loss: 0.7380745589733124\n",
            "Epoch 37/100, Loss: 0.6986291348934174\n",
            "Epoch 38/100, Loss: 0.6770074754953385\n",
            "Epoch 39/100, Loss: 0.675429955124855\n",
            "Epoch 40/100, Loss: 0.6598624944686889\n",
            "Epoch 41/100, Loss: 0.6477529004216194\n",
            "Epoch 42/100, Loss: 0.6421068042516709\n",
            "Epoch 43/100, Loss: 0.6293414935469628\n",
            "Epoch 44/100, Loss: 0.6237191408872604\n",
            "Epoch 45/100, Loss: 0.6239313602447509\n",
            "Epoch 46/100, Loss: 0.6001542344689369\n",
            "Epoch 47/100, Loss: 0.6070224732160568\n",
            "Epoch 48/100, Loss: 0.5948679596185684\n",
            "Epoch 49/100, Loss: 0.5846927791833878\n",
            "Epoch 50/100, Loss: 0.5646365940570831\n",
            "Epoch 51/100, Loss: 0.5873501390218735\n",
            "Epoch 52/100, Loss: 0.553849795460701\n",
            "Epoch 53/100, Loss: 0.5324326142668724\n",
            "Epoch 54/100, Loss: 0.5575585693120957\n",
            "Epoch 55/100, Loss: 0.5804982244968414\n",
            "Epoch 56/100, Loss: 0.5763030409812927\n",
            "Epoch 57/100, Loss: 0.508410282433033\n",
            "Epoch 58/100, Loss: 0.49423614889383316\n",
            "Epoch 59/100, Loss: 0.5040651813149453\n",
            "Epoch 60/100, Loss: 0.4835072487592697\n",
            "Epoch 61/100, Loss: 0.49367715716362\n",
            "Epoch 62/100, Loss: 0.48061876744031906\n",
            "Epoch 63/100, Loss: 0.46799769848585127\n",
            "Epoch 64/100, Loss: 0.4953801169991493\n",
            "Epoch 65/100, Loss: 0.49410035759210585\n",
            "Epoch 66/100, Loss: 0.4644318625330925\n",
            "Epoch 67/100, Loss: 0.4279649630188942\n",
            "Epoch 68/100, Loss: 0.456419488042593\n",
            "Epoch 69/100, Loss: 0.4176155596971512\n",
            "Epoch 70/100, Loss: 0.41543668508529663\n",
            "Epoch 71/100, Loss: 0.48230611383914945\n",
            "Epoch 72/100, Loss: 0.42281789779663087\n",
            "Epoch 73/100, Loss: 0.4409614592790604\n",
            "Epoch 74/100, Loss: 0.4040126845240593\n",
            "Epoch 75/100, Loss: 0.41115943193435667\n",
            "Epoch 76/100, Loss: 0.36633558124303817\n",
            "Epoch 77/100, Loss: 0.3695995703339577\n",
            "Epoch 78/100, Loss: 0.3819689445197582\n",
            "Epoch 79/100, Loss: 0.37277204245328904\n",
            "Epoch 80/100, Loss: 0.3540074281394482\n",
            "Epoch 81/100, Loss: 0.3577993378043175\n",
            "Epoch 82/100, Loss: 0.3433275938034058\n",
            "Epoch 83/100, Loss: 0.3279236391186714\n",
            "Epoch 84/100, Loss: 0.34551513865590094\n",
            "Epoch 85/100, Loss: 0.32868498340249064\n",
            "Epoch 86/100, Loss: 0.32191402837634087\n",
            "Epoch 87/100, Loss: 0.321578811109066\n",
            "Epoch 88/100, Loss: 0.3336635150015354\n",
            "Epoch 89/100, Loss: 0.29764760807156565\n",
            "Epoch 90/100, Loss: 0.29751444011926653\n",
            "Epoch 91/100, Loss: 0.28980364799499514\n",
            "Epoch 92/100, Loss: 0.28776234984397886\n",
            "Epoch 93/100, Loss: 0.2721117578446865\n",
            "Epoch 94/100, Loss: 0.29262520298361777\n",
            "Epoch 95/100, Loss: 0.27168059200048444\n",
            "Epoch 96/100, Loss: 0.30351471342146397\n",
            "Epoch 97/100, Loss: 0.276367349177599\n",
            "Epoch 98/100, Loss: 0.2910291448235512\n",
            "Epoch 99/100, Loss: 0.28904606252908704\n",
            "Epoch 100/100, Loss: 0.26530031487345695\n",
            "Accuracy on img3: 77.0\n"
          ]
        }
      ],
      "source": [
        "# Function to perform training and evaluation\n",
        "def run_experiment(train_loader, test_loader, model):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    train_model(model, train_loader, criterion, optimizer, epochs=100)\n",
        "    accuracy = evaluate_model(model, test_loader)\n",
        "    return accuracy\n",
        "\n",
        "# Train and evaluate on img1\n",
        "print(\"Training and evaluating on img1:\")\n",
        "model1 = LeNet5(num_classes=4)\n",
        "accuracy_img1 = run_experiment(img1_train_loader, img1_test_loader, model1)\n",
        "print('Accuracy on img1:', accuracy_img1)\n",
        "\n",
        "# Train and evaluate on img2\n",
        "print(\"Training and evaluating on img2:\")\n",
        "model2 = LeNet5(num_classes=4)\n",
        "accuracy_img2 = run_experiment(img2_train_loader, img2_test_loader, model2)\n",
        "print('Accuracy on img2:', accuracy_img2)\n",
        "\n",
        "# Train and evaluate on img3\n",
        "print(\"Training and evaluating on img3:\")\n",
        "model3 = LeNet5(num_classes=4)\n",
        "accuracy_img3 = run_experiment(img3_train_loader, img3_test_loader, model3)\n",
        "print('Accuracy on img3:', accuracy_img3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2A76ZImufC6w"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"\\n    # Show Result\\n    plt.figure(figsize=(12, 8))\\n    plt.suptitle(f\\'Image No. {str(i+1).zfill(5)}\\', fontsize=16)\\n\\n    # First Row\\n    plt.subplot(2, 3, 1)\\n    plt.title(\\'Gradient\\')\\n    plt.axis(\\'off\\')\\n    plt.imshow(image1.astype(np.uint8))\\n\\n    plt.subplot(2, 3, 2)\\n    plt.title(\\'Noise\\')\\n    plt.axis(\\'off\\')\\n    plt.imshow(image2.astype(np.uint8), cmap=None)\\n\\n    plt.subplot(2, 3, 3)\\n    plt.title(\\'Spotlight\\')\\n    plt.axis(\\'off\\')\\n    plt.imshow(image3.astype(np.uint8), cmap=None)\\n\\n    # Second Row\\n    plt.subplot(2, 3, 4)\\n    plt.title(\\'Average Fusion\\')\\n    plt.axis(\\'off\\')\\n    plt.imshow(fused_average.astype(np.uint8), cmap=None)\\n\\n    plt.subplot(2, 3, 5)\\n    plt.title(\\'Max Selection Fusion\\')\\n    plt.axis(\\'off\\')\\n    plt.imshow(fused_max.astype(np.uint8), cmap=None)\\n\\n    plt.subplot(2, 3, 6)\\n    plt.title(\\'Min Selection Fusion\\')\\n    plt.axis(\\'off\\')\\n    plt.imshow(fused_min.astype(np.uint8), cmap=None)\\n\\n    plt.tight_layout()\\n    plt.show()\\n'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from skimage.io import imread, imshow, imsave\n",
        "from skimage.transform import resize\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_path = 'Imagefusion_Dataset'\n",
        "\n",
        "# Define the folders for each sensor and fused images\n",
        "img1_folder = os.path.join(dataset_path, 'img', 'img1')\n",
        "img2_folder = os.path.join(dataset_path, 'img', 'img2')\n",
        "img3_folder = os.path.join(dataset_path, 'img', 'img3')\n",
        "fused_folder = os.path.join(dataset_path, 'fused')\n",
        "\n",
        "# Create the fused folder if it doesn't exist\n",
        "if not os.path.exists(fused_folder):\n",
        "    os.makedirs(fused_folder)\n",
        "\n",
        "# Get a list of all image files in each folder\n",
        "img1_files = [f for f in os.listdir(img1_folder) if f.endswith('.png')]\n",
        "img2_files = [f for f in os.listdir(img2_folder) if f.endswith('.png')]\n",
        "img3_files = [f for f in os.listdir(img3_folder) if f.endswith('.png')]\n",
        "\n",
        "# Methods\n",
        "def average_fusion(image1, image2, image3):\n",
        "    if len(image1.shape) == 3:\n",
        "        image1 = image1.mean(axis = 2)\n",
        "    if len(image2.shape) == 3:\n",
        "        image2 = image2.mean(axis = 2)\n",
        "    if len(image3.shape) == 3:\n",
        "        image3 = image3.mean(axis = 2)\n",
        "    return (image1 + image2 + image3) / 3\n",
        "\n",
        "def max_selection_fusion(image1, image2, image3):\n",
        "    if len(image1.shape) == 3:\n",
        "        image1 = image1.max(axis = 2)\n",
        "    if len(image2.shape) == 3:\n",
        "        image2 = image2.max(axis = 2)\n",
        "    if len(image3.shape) == 3:\n",
        "        image3 = image3.max(axis = 2)\n",
        "    return np.maximum(np.maximum(image1, image2), image3)\n",
        "\n",
        "def min_selection_fusion(image1, image2, image3):\n",
        "    if len(image1.shape) == 3:\n",
        "        image1 = image1.min(axis = 2)\n",
        "    if len(image2.shape) == 3:\n",
        "        image2 = image2.min(axis = 2)\n",
        "    if len(image3.shape) == 3:\n",
        "        image3 = image3.min(axis = 2)\n",
        "    return np.minimum(np.minimum(image1, image2), image3)\n",
        "\n",
        "fused_images= []\n",
        "\n",
        "# Apply Fusion to all images\n",
        "for i, (img1_file, img2_file, img3_file) in enumerate(zip(img1_files, img2_files, img3_files)):\n",
        "    image1 = imread(os.path.join(img1_folder, img1_file)).astype(float)\n",
        "    image2 = imread(os.path.join(img2_folder, img2_file)).astype(float)\n",
        "    image3 = imread(os.path.join(img3_folder, img3_file)).astype(float)\n",
        "\n",
        "    fused_average = average_fusion(image1, image2, image3)\n",
        "    fused_max = max_selection_fusion(image1, image2, image3)\n",
        "    fused_min = min_selection_fusion(image1, image2, image3)\n",
        "\n",
        "    # Store the fused average images in the list\n",
        "    fused_images.append(fused_max)\n",
        "\n",
        "    # Save the fused average images to the specified directory\n",
        "    fused_image_filename = os.path.join(fused_folder, f'{str(i).zfill(5)}.png')\n",
        "    imsave(fused_image_filename, fused_average.astype(np.uint8))\n",
        "\n",
        "\"\"\"\"\n",
        "    # Show Result\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.suptitle(f'Image No. {str(i+1).zfill(5)}', fontsize=16)\n",
        "\n",
        "    # First Row\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.title('Gradient')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image1.astype(np.uint8))\n",
        "\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.title('Noise')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image2.astype(np.uint8), cmap=None)\n",
        "\n",
        "    plt.subplot(2, 3, 3)\n",
        "    plt.title('Spotlight')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image3.astype(np.uint8), cmap=None)\n",
        "\n",
        "    # Second Row\n",
        "    plt.subplot(2, 3, 4)\n",
        "    plt.title('Average Fusion')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(fused_average.astype(np.uint8), cmap=None)\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    plt.title('Max Selection Fusion')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(fused_max.astype(np.uint8), cmap=None)\n",
        "\n",
        "    plt.subplot(2, 3, 6)\n",
        "    plt.title('Min Selection Fusion')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(fused_min.astype(np.uint8), cmap=None)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i6q2qgVfC2n",
        "outputId": "38daa0cc-91f4-4f1e-bf71-28fca364c25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model 1...\n",
            "Epoch 1/100, Loss: 1.3850075098184438\n",
            "Epoch 2/100, Loss: 1.373026361832252\n",
            "Epoch 3/100, Loss: 1.3595608381124644\n",
            "Epoch 4/100, Loss: 1.3320808227245624\n",
            "Epoch 5/100, Loss: 1.2831127460186298\n",
            "Epoch 6/100, Loss: 1.1971730177219098\n",
            "Epoch 7/100, Loss: 1.1618382288859441\n",
            "Epoch 8/100, Loss: 1.1552633138803334\n",
            "Epoch 9/100, Loss: 1.2025339236626258\n",
            "Epoch 10/100, Loss: 1.1860182193609385\n",
            "Epoch 11/100, Loss: 1.1370316468752348\n",
            "Epoch 12/100, Loss: 1.1007267878605769\n",
            "Epoch 13/100, Loss: 1.0898940975849445\n",
            "Epoch 14/100, Loss: 1.0819918513298035\n",
            "Epoch 15/100, Loss: 1.072713287977072\n",
            "Epoch 16/100, Loss: 1.0432592126039357\n",
            "Epoch 17/100, Loss: 1.0676968968831575\n",
            "Epoch 18/100, Loss: 1.0651744558260992\n",
            "Epoch 19/100, Loss: 1.0234415256060088\n",
            "Epoch 20/100, Loss: 1.0080337386864882\n",
            "Epoch 21/100, Loss: 0.9965798808978155\n",
            "Epoch 22/100, Loss: 1.001216274041396\n",
            "Epoch 23/100, Loss: 0.9616299775930551\n",
            "Epoch 24/100, Loss: 0.9508884732539837\n",
            "Epoch 25/100, Loss: 0.9653672667650076\n",
            "Epoch 26/100, Loss: 0.9303593635559082\n",
            "Epoch 27/100, Loss: 0.9093316243245051\n",
            "Epoch 28/100, Loss: 0.9015053969163161\n",
            "Epoch 29/100, Loss: 0.9224470578707181\n",
            "Epoch 30/100, Loss: 0.9093231558799744\n",
            "Epoch 31/100, Loss: 0.8634127424313471\n",
            "Epoch 32/100, Loss: 0.860409635763902\n",
            "Epoch 33/100, Loss: 0.8429930439362159\n",
            "Epoch 34/100, Loss: 0.8372308336771451\n",
            "Epoch 35/100, Loss: 0.8186126534755414\n",
            "Epoch 36/100, Loss: 0.8104740060292758\n",
            "Epoch 37/100, Loss: 0.7879935273757348\n",
            "Epoch 38/100, Loss: 0.7729542576349698\n",
            "Epoch 39/100, Loss: 0.7786991275273837\n",
            "Epoch 40/100, Loss: 0.7867929889605596\n",
            "Epoch 41/100, Loss: 0.7616398884699895\n",
            "Epoch 42/100, Loss: 0.7582176052607023\n",
            "Epoch 43/100, Loss: 0.7306117965624883\n",
            "Epoch 44/100, Loss: 0.7367656506024874\n",
            "Epoch 45/100, Loss: 0.6966908299005948\n",
            "Epoch 46/100, Loss: 0.6836887506338266\n",
            "Epoch 47/100, Loss: 0.6723270737207853\n",
            "Epoch 48/100, Loss: 0.6515995676700885\n",
            "Epoch 49/100, Loss: 0.6278928564145014\n",
            "Epoch 50/100, Loss: 0.60933574117147\n",
            "Epoch 51/100, Loss: 0.6270154279011947\n",
            "Epoch 52/100, Loss: 0.5953508225771097\n",
            "Epoch 53/100, Loss: 0.6034079010670002\n",
            "Epoch 54/100, Loss: 0.5724365138090574\n",
            "Epoch 55/100, Loss: 0.5855215489864349\n",
            "Epoch 56/100, Loss: 0.560337266096702\n",
            "Epoch 57/100, Loss: 0.5405765955264752\n",
            "Epoch 58/100, Loss: 0.5410753213442289\n",
            "Epoch 59/100, Loss: 0.517777470441965\n",
            "Epoch 60/100, Loss: 0.5202731352586013\n",
            "Epoch 61/100, Loss: 0.49820149403352004\n",
            "Epoch 62/100, Loss: 0.4794637606694148\n",
            "Epoch 63/100, Loss: 0.47169042321351856\n",
            "Epoch 64/100, Loss: 0.4589683413505554\n",
            "Epoch 65/100, Loss: 0.4596074636165912\n",
            "Epoch 66/100, Loss: 0.4428961185308603\n",
            "Epoch 67/100, Loss: 0.43015097884031445\n",
            "Epoch 68/100, Loss: 0.4278182089328766\n",
            "Epoch 69/100, Loss: 0.4077481444065387\n",
            "Epoch 70/100, Loss: 0.39790958166122437\n",
            "Epoch 71/100, Loss: 0.3884647007171924\n",
            "Epoch 72/100, Loss: 0.3824402323135963\n",
            "Epoch 73/100, Loss: 0.3784146767396193\n",
            "Epoch 74/100, Loss: 0.38557448295446545\n",
            "Epoch 75/100, Loss: 0.3953760793575874\n",
            "Epoch 76/100, Loss: 0.3675149713571255\n",
            "Epoch 77/100, Loss: 0.4326314673973964\n",
            "Epoch 78/100, Loss: 0.36153951860391176\n",
            "Epoch 79/100, Loss: 0.34277487718141997\n",
            "Epoch 80/100, Loss: 0.3308578867178697\n",
            "Epoch 81/100, Loss: 0.3012287410405966\n",
            "Epoch 82/100, Loss: 0.28972644874682796\n",
            "Epoch 83/100, Loss: 0.29602202199972594\n",
            "Epoch 84/100, Loss: 0.2691604219950162\n",
            "Epoch 85/100, Loss: 0.26595781399653506\n",
            "Epoch 86/100, Loss: 0.27404905741031355\n",
            "Epoch 87/100, Loss: 0.245451046870305\n",
            "Epoch 88/100, Loss: 0.24470365047454834\n",
            "Epoch 89/100, Loss: 0.2235953968304854\n",
            "Epoch 90/100, Loss: 0.2293980706196565\n",
            "Epoch 91/100, Loss: 0.21463783773092124\n",
            "Epoch 92/100, Loss: 0.21159836191397446\n",
            "Epoch 93/100, Loss: 0.21850280005198258\n",
            "Epoch 94/100, Loss: 0.21801536816817063\n",
            "Epoch 95/100, Loss: 0.2043472150197396\n",
            "Epoch 96/100, Loss: 0.17380586896951383\n",
            "Epoch 97/100, Loss: 0.17574317122881228\n",
            "Epoch 98/100, Loss: 0.17897438372556979\n",
            "Epoch 99/100, Loss: 0.16213793479479277\n",
            "Epoch 100/100, Loss: 0.16186787703862557\n",
            "Training model 2...\n",
            "Epoch 1/100, Loss: 1.3859554804288423\n",
            "Epoch 2/100, Loss: 1.3674961420205922\n",
            "Epoch 3/100, Loss: 1.3226110935211182\n",
            "Epoch 4/100, Loss: 1.2147833292300885\n",
            "Epoch 5/100, Loss: 1.122881857248453\n",
            "Epoch 6/100, Loss: 1.1208460101714501\n",
            "Epoch 7/100, Loss: 1.106625722004817\n",
            "Epoch 8/100, Loss: 1.0408028822678785\n",
            "Epoch 9/100, Loss: 1.0485258927712073\n",
            "Epoch 10/100, Loss: 1.0159569061719453\n",
            "Epoch 11/100, Loss: 1.010490215741671\n",
            "Epoch 12/100, Loss: 0.9959998956093421\n",
            "Epoch 13/100, Loss: 1.046925310905163\n",
            "Epoch 14/100, Loss: 1.0380896650827849\n",
            "Epoch 15/100, Loss: 1.0016256341567407\n",
            "Epoch 16/100, Loss: 0.9733318182138296\n",
            "Epoch 17/100, Loss: 0.9580355882644653\n",
            "Epoch 18/100, Loss: 0.9437149029511672\n",
            "Epoch 19/100, Loss: 0.932674779341771\n",
            "Epoch 20/100, Loss: 0.9502224509532635\n",
            "Epoch 21/100, Loss: 0.9171042167223417\n",
            "Epoch 22/100, Loss: 0.9444465041160583\n",
            "Epoch 23/100, Loss: 0.923896693266355\n",
            "Epoch 24/100, Loss: 0.9054457407731277\n",
            "Epoch 25/100, Loss: 0.8898396904651935\n",
            "Epoch 26/100, Loss: 0.9518089248583868\n",
            "Epoch 27/100, Loss: 0.8862839616261996\n",
            "Epoch 28/100, Loss: 0.8867671122917762\n",
            "Epoch 29/100, Loss: 0.875879535308251\n",
            "Epoch 30/100, Loss: 0.8606161704430213\n",
            "Epoch 31/100, Loss: 0.8692285189261804\n",
            "Epoch 32/100, Loss: 0.8728728294372559\n",
            "Epoch 33/100, Loss: 0.9208678878270663\n",
            "Epoch 34/100, Loss: 0.8463055949944717\n",
            "Epoch 35/100, Loss: 0.8676643371582031\n",
            "Epoch 36/100, Loss: 0.8520645269980798\n",
            "Epoch 37/100, Loss: 0.8342533386670626\n",
            "Epoch 38/100, Loss: 0.8743743850634649\n",
            "Epoch 39/100, Loss: 0.8428057065376868\n",
            "Epoch 40/100, Loss: 0.8005004983681899\n",
            "Epoch 41/100, Loss: 0.8188793796759385\n",
            "Epoch 42/100, Loss: 0.8447465071311364\n",
            "Epoch 43/100, Loss: 0.87911233993677\n",
            "Epoch 44/100, Loss: 0.8034318318733802\n",
            "Epoch 45/100, Loss: 0.7898993217028104\n",
            "Epoch 46/100, Loss: 0.7934740369136517\n",
            "Epoch 47/100, Loss: 0.8170706996550927\n",
            "Epoch 48/100, Loss: 0.7667578917283279\n",
            "Epoch 49/100, Loss: 0.7838073877187876\n",
            "Epoch 50/100, Loss: 0.7733920308259817\n",
            "Epoch 51/100, Loss: 0.7519346200502836\n",
            "Epoch 52/100, Loss: 0.7400531081052927\n",
            "Epoch 53/100, Loss: 0.7666542988557082\n",
            "Epoch 54/100, Loss: 0.8381069440108079\n",
            "Epoch 55/100, Loss: 0.7956068790875949\n",
            "Epoch 56/100, Loss: 0.7259145562465374\n",
            "Epoch 57/100, Loss: 0.7239794776989863\n",
            "Epoch 58/100, Loss: 0.7287094730597276\n",
            "Epoch 59/100, Loss: 0.7063387357271634\n",
            "Epoch 60/100, Loss: 0.7034253294651325\n",
            "Epoch 61/100, Loss: 0.7201101734088018\n",
            "Epoch 62/100, Loss: 0.6855020614770743\n",
            "Epoch 63/100, Loss: 0.6911513346892136\n",
            "Epoch 64/100, Loss: 0.723515496804164\n",
            "Epoch 65/100, Loss: 0.6954108293239887\n",
            "Epoch 66/100, Loss: 0.6960041293731103\n",
            "Epoch 67/100, Loss: 0.673286680991833\n",
            "Epoch 68/100, Loss: 0.6723674673300523\n",
            "Epoch 69/100, Loss: 0.7933268409508926\n",
            "Epoch 70/100, Loss: 0.6758371866666354\n",
            "Epoch 71/100, Loss: 0.6582324321453388\n",
            "Epoch 72/100, Loss: 0.6560768576768728\n",
            "Epoch 73/100, Loss: 0.6568460281078632\n",
            "Epoch 74/100, Loss: 0.7458095779785743\n",
            "Epoch 75/100, Loss: 0.6833332318526047\n",
            "Epoch 76/100, Loss: 0.6792075886176183\n",
            "Epoch 77/100, Loss: 0.6475957127717825\n",
            "Epoch 78/100, Loss: 0.6457045261676495\n",
            "Epoch 79/100, Loss: 0.7041210119540875\n",
            "Epoch 80/100, Loss: 0.6939896528537457\n",
            "Epoch 81/100, Loss: 0.6244420042404761\n",
            "Epoch 82/100, Loss: 0.6383662315515372\n",
            "Epoch 83/100, Loss: 0.6645872226128211\n",
            "Epoch 84/100, Loss: 0.6563682005955622\n",
            "Epoch 85/100, Loss: 0.6262428989777198\n",
            "Epoch 86/100, Loss: 0.6027037776433505\n",
            "Epoch 87/100, Loss: 0.6096121210318345\n",
            "Epoch 88/100, Loss: 0.6560289263725281\n",
            "Epoch 89/100, Loss: 0.6086649321592771\n",
            "Epoch 90/100, Loss: 0.5916476341394278\n",
            "Epoch 91/100, Loss: 0.616203078856835\n",
            "Epoch 92/100, Loss: 0.6114953458309174\n",
            "Epoch 93/100, Loss: 0.599229810329584\n",
            "Epoch 94/100, Loss: 0.5812965287612035\n",
            "Epoch 95/100, Loss: 0.5738660234671372\n",
            "Epoch 96/100, Loss: 0.6102846494087806\n",
            "Epoch 97/100, Loss: 0.632429627271799\n",
            "Epoch 98/100, Loss: 0.583272995857092\n",
            "Epoch 99/100, Loss: 0.5539217132788438\n",
            "Epoch 100/100, Loss: 0.5578719973564148\n",
            "Training model 3...\n",
            "Epoch 1/100, Loss: 1.3754006899320161\n",
            "Epoch 2/100, Loss: 1.3268674795444195\n",
            "Epoch 3/100, Loss: 1.1910299337827241\n",
            "Epoch 4/100, Loss: 1.0949178383900569\n",
            "Epoch 5/100, Loss: 1.0383654236793518\n",
            "Epoch 6/100, Loss: 1.00532466173172\n",
            "Epoch 7/100, Loss: 0.9996157334401057\n",
            "Epoch 8/100, Loss: 0.9792679915061364\n",
            "Epoch 9/100, Loss: 0.9788632576282208\n",
            "Epoch 10/100, Loss: 0.9588943811563345\n",
            "Epoch 11/100, Loss: 0.9749378286875211\n",
            "Epoch 12/100, Loss: 1.0194106652186468\n",
            "Epoch 13/100, Loss: 1.0247828731170068\n",
            "Epoch 14/100, Loss: 0.9549591357891376\n",
            "Epoch 15/100, Loss: 0.9421721146656916\n",
            "Epoch 16/100, Loss: 0.9539702947323139\n",
            "Epoch 17/100, Loss: 0.9509608653875498\n",
            "Epoch 18/100, Loss: 0.9336080321898828\n",
            "Epoch 19/100, Loss: 0.9262488300983722\n",
            "Epoch 20/100, Loss: 0.9318604148351229\n",
            "Epoch 21/100, Loss: 0.9159933832975534\n",
            "Epoch 22/100, Loss: 0.915791025528541\n",
            "Epoch 23/100, Loss: 0.90955873636099\n",
            "Epoch 24/100, Loss: 0.9303064942359924\n",
            "Epoch 25/100, Loss: 0.9138670151050274\n",
            "Epoch 26/100, Loss: 0.8942344326239365\n",
            "Epoch 27/100, Loss: 0.8908478296720065\n",
            "Epoch 28/100, Loss: 0.881742692910708\n",
            "Epoch 29/100, Loss: 0.8843766313332778\n",
            "Epoch 30/100, Loss: 0.860537235553448\n",
            "Epoch 31/100, Loss: 0.8574904203414917\n",
            "Epoch 32/100, Loss: 0.8937371923373296\n",
            "Epoch 33/100, Loss: 0.8653379724575923\n",
            "Epoch 34/100, Loss: 0.8351059418458205\n",
            "Epoch 35/100, Loss: 0.8452874834720905\n",
            "Epoch 36/100, Loss: 0.8252694423382099\n",
            "Epoch 37/100, Loss: 0.8304678339224595\n",
            "Epoch 38/100, Loss: 0.8103380570044885\n",
            "Epoch 39/100, Loss: 0.8493511860187237\n",
            "Epoch 40/100, Loss: 0.8356822454012357\n",
            "Epoch 41/100, Loss: 0.82902847803556\n",
            "Epoch 42/100, Loss: 0.7991789395992572\n",
            "Epoch 43/100, Loss: 0.8259340249575101\n",
            "Epoch 44/100, Loss: 0.8369390185062702\n",
            "Epoch 45/100, Loss: 0.8249097604017991\n",
            "Epoch 46/100, Loss: 0.8001178686435406\n",
            "Epoch 47/100, Loss: 0.8141836111362164\n",
            "Epoch 48/100, Loss: 0.8069537419539231\n",
            "Epoch 49/100, Loss: 0.7997135749230018\n",
            "Epoch 50/100, Loss: 0.7742251799656794\n",
            "Epoch 51/100, Loss: 0.777970919242272\n",
            "Epoch 52/100, Loss: 0.7493948065317594\n",
            "Epoch 53/100, Loss: 0.7386969373776362\n",
            "Epoch 54/100, Loss: 0.7446685433387756\n",
            "Epoch 55/100, Loss: 0.756019298846905\n",
            "Epoch 56/100, Loss: 0.7469744957410372\n",
            "Epoch 57/100, Loss: 0.7258085333384\n",
            "Epoch 58/100, Loss: 0.7312423082498404\n",
            "Epoch 59/100, Loss: 0.7721622173602765\n",
            "Epoch 60/100, Loss: 0.7301148863939139\n",
            "Epoch 61/100, Loss: 0.7366540890473586\n",
            "Epoch 62/100, Loss: 0.7367964065991915\n",
            "Epoch 63/100, Loss: 0.7215823439451364\n",
            "Epoch 64/100, Loss: 0.7244409597837008\n",
            "Epoch 65/100, Loss: 0.7085580229759216\n",
            "Epoch 66/100, Loss: 0.6986396817060617\n",
            "Epoch 67/100, Loss: 0.739234773012308\n",
            "Epoch 68/100, Loss: 0.7026612598162431\n",
            "Epoch 69/100, Loss: 0.7287070476091825\n",
            "Epoch 70/100, Loss: 0.68012352173145\n",
            "Epoch 71/100, Loss: 0.7054251386569097\n",
            "Epoch 72/100, Loss: 0.6594738364219666\n",
            "Epoch 73/100, Loss: 0.6664204780872052\n",
            "Epoch 74/100, Loss: 0.65364320232318\n",
            "Epoch 75/100, Loss: 0.6685600876808167\n",
            "Epoch 76/100, Loss: 0.64217075247031\n",
            "Epoch 77/100, Loss: 0.6906712788801926\n",
            "Epoch 78/100, Loss: 0.6788689539982722\n",
            "Epoch 79/100, Loss: 0.6584843122042142\n",
            "Epoch 80/100, Loss: 0.6652397421690134\n",
            "Epoch 81/100, Loss: 0.64559844823984\n",
            "Epoch 82/100, Loss: 0.6551765386874859\n",
            "Epoch 83/100, Loss: 0.660691859630438\n",
            "Epoch 84/100, Loss: 0.6880751985770005\n",
            "Epoch 85/100, Loss: 0.6356051564216614\n",
            "Epoch 86/100, Loss: 0.6258431810599107\n",
            "Epoch 87/100, Loss: 0.6256373157868018\n",
            "Epoch 88/100, Loss: 0.6062733485148504\n",
            "Epoch 89/100, Loss: 0.6143182607797476\n",
            "Epoch 90/100, Loss: 0.6196995836037856\n",
            "Epoch 91/100, Loss: 0.5866983785079076\n",
            "Epoch 92/100, Loss: 0.6066682934761047\n",
            "Epoch 93/100, Loss: 0.5855438159062312\n",
            "Epoch 94/100, Loss: 0.561756432056427\n",
            "Epoch 95/100, Loss: 0.5681717441632197\n",
            "Epoch 96/100, Loss: 0.5917678681703714\n",
            "Epoch 97/100, Loss: 0.5713716126405276\n",
            "Epoch 98/100, Loss: 0.5709112355342278\n",
            "Epoch 99/100, Loss: 0.5708843698868384\n",
            "Epoch 100/100, Loss: 0.5664340784916511\n",
            "Training fused model...\n",
            "Epoch 1/100, Loss: 1.3801385072561412\n",
            "Epoch 2/100, Loss: 1.3553969676677997\n",
            "Epoch 3/100, Loss: 1.294785187794612\n",
            "Epoch 4/100, Loss: 1.1862521446668184\n",
            "Epoch 5/100, Loss: 1.0910480572627141\n",
            "Epoch 6/100, Loss: 1.1066410541534424\n",
            "Epoch 7/100, Loss: 1.0509846210479736\n",
            "Epoch 8/100, Loss: 1.02857840519685\n",
            "Epoch 9/100, Loss: 0.9986085570775546\n",
            "Epoch 10/100, Loss: 0.982252130141625\n",
            "Epoch 11/100, Loss: 1.00935481603329\n",
            "Epoch 12/100, Loss: 1.0070404823009784\n",
            "Epoch 13/100, Loss: 0.9570564444248493\n",
            "Epoch 14/100, Loss: 0.9843977827292222\n",
            "Epoch 15/100, Loss: 0.9659172434073228\n",
            "Epoch 16/100, Loss: 0.9206787989689753\n",
            "Epoch 17/100, Loss: 0.9030799269676208\n",
            "Epoch 18/100, Loss: 0.8865988483795753\n",
            "Epoch 19/100, Loss: 0.8543145931684054\n",
            "Epoch 20/100, Loss: 0.8569414799030011\n",
            "Epoch 21/100, Loss: 0.8233991311146662\n",
            "Epoch 22/100, Loss: 0.816059791124784\n",
            "Epoch 23/100, Loss: 0.8499866311366742\n",
            "Epoch 24/100, Loss: 0.7952982645768386\n",
            "Epoch 25/100, Loss: 0.7657314172157874\n",
            "Epoch 26/100, Loss: 0.7580089523242071\n",
            "Epoch 27/100, Loss: 0.7383734125357407\n",
            "Epoch 28/100, Loss: 0.8000488189550546\n",
            "Epoch 29/100, Loss: 0.729552530325376\n",
            "Epoch 30/100, Loss: 0.7364137035149795\n",
            "Epoch 31/100, Loss: 0.7088425847200247\n",
            "Epoch 32/100, Loss: 0.7009126498148992\n",
            "Epoch 33/100, Loss: 0.6829673418631921\n",
            "Epoch 34/100, Loss: 0.698683541554671\n",
            "Epoch 35/100, Loss: 0.6962422820237967\n",
            "Epoch 36/100, Loss: 0.7594305322720454\n",
            "Epoch 37/100, Loss: 0.7470242656194247\n",
            "Epoch 38/100, Loss: 0.6872315956996038\n",
            "Epoch 39/100, Loss: 0.7009999201847956\n",
            "Epoch 40/100, Loss: 0.6774646456425006\n",
            "Epoch 41/100, Loss: 0.663213496024792\n",
            "Epoch 42/100, Loss: 0.6501402121323806\n",
            "Epoch 43/100, Loss: 0.6560671100249658\n",
            "Epoch 44/100, Loss: 0.680236619252425\n",
            "Epoch 45/100, Loss: 0.6907701400610117\n",
            "Epoch 46/100, Loss: 0.6459073103391207\n",
            "Epoch 47/100, Loss: 0.5994639992713928\n",
            "Epoch 48/100, Loss: 0.6048002563990079\n",
            "Epoch 49/100, Loss: 0.6338423032027024\n",
            "Epoch 50/100, Loss: 0.6170663604369531\n",
            "Epoch 51/100, Loss: 0.6364453434944153\n",
            "Epoch 52/100, Loss: 0.5928618976703057\n",
            "Epoch 53/100, Loss: 0.591777659379519\n",
            "Epoch 54/100, Loss: 0.5908771455287933\n",
            "Epoch 55/100, Loss: 0.5827340896313007\n",
            "Epoch 56/100, Loss: 0.5449395684095529\n",
            "Epoch 57/100, Loss: 0.5538805769040034\n",
            "Epoch 58/100, Loss: 0.5460288432928232\n",
            "Epoch 59/100, Loss: 0.5750060310730567\n",
            "Epoch 60/100, Loss: 0.5579567414063674\n",
            "Epoch 61/100, Loss: 0.5125916531452765\n",
            "Epoch 62/100, Loss: 0.5059749667461102\n",
            "Epoch 63/100, Loss: 0.5334368829543774\n",
            "Epoch 64/100, Loss: 0.5531114683701441\n",
            "Epoch 65/100, Loss: 0.514067108814533\n",
            "Epoch 66/100, Loss: 0.4923392350857074\n",
            "Epoch 67/100, Loss: 0.47527013604457563\n",
            "Epoch 68/100, Loss: 0.4834993573335501\n",
            "Epoch 69/100, Loss: 0.4938504650042607\n",
            "Epoch 70/100, Loss: 0.4870366156101227\n",
            "Epoch 71/100, Loss: 0.46317429955189043\n",
            "Epoch 72/100, Loss: 0.440605308000858\n",
            "Epoch 73/100, Loss: 0.4367644557586083\n",
            "Epoch 74/100, Loss: 0.42757192024817836\n",
            "Epoch 75/100, Loss: 0.4420055586558122\n",
            "Epoch 76/100, Loss: 0.42583970381663394\n",
            "Epoch 77/100, Loss: 0.4307550031405229\n",
            "Epoch 78/100, Loss: 0.40566781850961536\n",
            "Epoch 79/100, Loss: 0.39134161059673017\n",
            "Epoch 80/100, Loss: 0.3998985726099748\n",
            "Epoch 81/100, Loss: 0.4187010962229509\n",
            "Epoch 82/100, Loss: 0.4041726772601788\n",
            "Epoch 83/100, Loss: 0.40655491673029387\n",
            "Epoch 84/100, Loss: 0.37492965505673337\n",
            "Epoch 85/100, Loss: 0.3616492129289187\n",
            "Epoch 86/100, Loss: 0.3554306121972891\n",
            "Epoch 87/100, Loss: 0.3845552263351587\n",
            "Epoch 88/100, Loss: 0.3775433072677025\n",
            "Epoch 89/100, Loss: 0.37692689895629883\n",
            "Epoch 90/100, Loss: 0.43362566370230454\n",
            "Epoch 91/100, Loss: 0.3536454760111295\n",
            "Epoch 92/100, Loss: 0.3302810134795996\n",
            "Epoch 93/100, Loss: 0.32618431403086734\n",
            "Epoch 94/100, Loss: 0.35656212041011226\n",
            "Epoch 95/100, Loss: 0.32131810027819413\n",
            "Epoch 96/100, Loss: 0.3317691156497368\n",
            "Epoch 97/100, Loss: 0.30806928185316235\n",
            "Epoch 98/100, Loss: 0.34750652198608106\n",
            "Epoch 99/100, Loss: 0.3193956155043382\n",
            "Epoch 100/100, Loss: 0.3091760151661359\n"
          ]
        }
      ],
      "source": [
        "class SingleSensorDataset(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = sorted(os.listdir(img_dir))\n",
        "        self.labels = [self.load_label(os.path.join(label_dir, f\"{os.path.splitext(img)[0]}.txt\")) for img in self.image_files]\n",
        "\n",
        "    def load_label(self, label_path):\n",
        "        if not os.path.exists(label_path):  \n",
        "            raise FileNotFoundError(f\"Label file not found: {label_path}\")  # Debugging step\n",
        "\n",
        "        with open(label_path, 'r') as file:\n",
        "            label = file.readline().strip()\n",
        "        return shape2number[label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.image_files[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "class ImageFusionDataset(Dataset):\n",
        "    def __init__(self, img1_dir, img2_dir, img3_dir, label_dir, transform=None):\n",
        "        self.img1_dir = img1_dir\n",
        "        self.img2_dir = img2_dir\n",
        "        self.img3_dir = img3_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = sorted(os.listdir(img1_dir))\n",
        "        self.labels = [self.load_label(img) for img in self.image_files]  # ✅ Only pass filename\n",
        "\n",
        "    def load_label(self, img_name):\n",
        "        label_path = os.path.join(self.label_dir, f\"{os.path.splitext(img_name)[0]}.txt\")  # ✅ Corrected path\n",
        "        if not os.path.exists(label_path):  \n",
        "            raise FileNotFoundError(f\"Label file not found: {label_path}\")  # Debugging step\n",
        "\n",
        "        with open(label_path, 'r') as file:\n",
        "            label = file.readline().strip()\n",
        "        return shape2number[label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1_path = os.path.join(self.img1_dir, self.image_files[idx])\n",
        "        img2_path = os.path.join(self.img2_dir, self.image_files[idx])\n",
        "        img3_path = os.path.join(self.img3_dir, self.image_files[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        img1 = Image.open(img1_path)\n",
        "        img2 = Image.open(img2_path)\n",
        "        img3 = Image.open(img3_path)\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "            img3 = self.transform(img3)\n",
        "\n",
        "        combined_img = torch.cat((img1, img2, img3), dim=0)\n",
        "        return combined_img, label\n",
        "\n",
        "dataset_path = \"Imagefusion_Dataset\"  \n",
        "\n",
        "img1_dir = os.path.join(dataset_path, 'img', 'img1')\n",
        "img2_dir = os.path.join(dataset_path, 'img', 'img2')\n",
        "img3_dir = os.path.join(dataset_path, 'img', 'img3')\n",
        "label_dir = os.path.join(dataset_path, 'label')  # ✅ This is correct\n",
        "\n",
        "dataset1 = SingleSensorDataset(img1_dir, label_dir, transform)\n",
        "dataset2 = SingleSensorDataset(img2_dir, label_dir, transform)\n",
        "dataset3 = SingleSensorDataset(img3_dir, label_dir, transform)\n",
        "\n",
        "# Split the datasets into training and testing sets\n",
        "train_size = int(0.8 * len(dataset1))\n",
        "test_size = len(dataset1) - train_size\n",
        "\n",
        "train_dataset1, test_dataset1 = random_split(dataset1, [train_size, test_size])\n",
        "train_dataset2, test_dataset2 = random_split(dataset2, [train_size, test_size])\n",
        "train_dataset3, test_dataset3 = random_split(dataset3, [train_size, test_size])\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "train_loader1 = DataLoader(train_dataset1, batch_size=batch_size, shuffle=True)\n",
        "test_loader1 = DataLoader(test_dataset1, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_loader2 = DataLoader(train_dataset2, batch_size=batch_size, shuffle=True)\n",
        "test_loader2 = DataLoader(test_dataset2, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_loader3 = DataLoader(train_dataset3, batch_size=batch_size, shuffle=True)\n",
        "test_loader3 = DataLoader(test_dataset3, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Create the fused dataset for the fused model\n",
        "fused_dataset = ImageFusionDataset(img1_dir, img2_dir, img3_dir, label_dir, transform)\n",
        "train_dataset_fused, test_dataset_fused = random_split(fused_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader_fused = DataLoader(train_dataset_fused, batch_size=batch_size, shuffle=True)\n",
        "test_loader_fused = DataLoader(test_dataset_fused, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# Define the LeNet-5 model\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes=4, input_channels=1):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 6, kernel_size=5, stride=1, padding=2)  # Adjusted for 1 input channel (grayscale)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
        "        self.fc1 = nn.Linear(16*6*6, 120)  # Adjusted input size to 16*6*6\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*6*6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Instantiate models for each sensor dataset\n",
        "model1 = LeNet5(num_classes=4)\n",
        "model2 = LeNet5(num_classes=4)\n",
        "model3 = LeNet5(num_classes=4)\n",
        "model_fusion = LeNet5(num_classes=4, input_channels=3)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
        "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
        "optimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n",
        "optimizer_fusion = optim.Adam(model_fusion.parameters(), lr=0.001)\n",
        "\n",
        "# Train the models\n",
        "\n",
        "print(\"Training model 1...\")\n",
        "train_model(model1, train_loader1, criterion, optimizer1, epochs=100)\n",
        "print(\"Training model 2...\")\n",
        "train_model(model2, train_loader2, criterion, optimizer2, epochs=100)\n",
        "print(\"Training model 3...\")\n",
        "train_model(model3, train_loader3, criterion, optimizer3, epochs=100)\n",
        "print(\"Training fused model...\")\n",
        "train_model(model_fusion, train_loader_fused, criterion, optimizer_fusion, epochs=100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QCORmhLfC0h",
        "outputId": "caad01f7-dc69-40a4-d55c-3aa65357cbca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model 1: 71.5\n",
            "Accuracy of model 2: 65.5\n",
            "Accuracy of model 3: 66.5\n",
            "Accuracy with low-level fusion: 77.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the models\n",
        "accuracy1 = evaluate_model(model1, test_loader1)\n",
        "accuracy2 = evaluate_model(model2, test_loader2)\n",
        "accuracy3 = evaluate_model(model3, test_loader3)\n",
        "accuracy_fusion = evaluate_model(model_fusion, test_loader_fused)\n",
        "\n",
        "print('Accuracy of model 1:', accuracy1)\n",
        "print('Accuracy of model 2:', accuracy2)\n",
        "print('Accuracy of model 3:', accuracy3)\n",
        "print('Accuracy with low-level fusion:', accuracy_fusion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X4v58RTfCx8",
        "outputId": "869b08f2-571a-41cc-95d4-538a59e64aec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with low and high level image fusion: 86.5\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Function to perform majority voting with tie breaker\n",
        "def majority_voting(models, test_loader):\n",
        "    model1, model2, model3, model_fusion = models\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "    model3.eval()\n",
        "    model_fusion.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            batch_size = images.size(0)\n",
        "            predictions = torch.zeros(batch_size, dtype=torch.long)\n",
        "            image1 = images[:, 0:1, :, :]\n",
        "            image2 = images[:, 1:2, :, :]\n",
        "            image3 = images[:, 2:3, :, :]\n",
        "\n",
        "            output1 = model1(image1)\n",
        "            output2 = model2(image2)\n",
        "            output3 = model3(image3)\n",
        "            output_fusion = model_fusion(images)\n",
        "\n",
        "            _, predicted1 = torch.max(output1, 1)\n",
        "            _, predicted2 = torch.max(output2, 1)\n",
        "            _, predicted3 = torch.max(output3, 1)\n",
        "            _, predicted_fusion = torch.max(output_fusion, 1)\n",
        "\n",
        "            stacked_preds = torch.stack((predicted1, predicted2, predicted3), dim=1)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                vote_counts = torch.bincount(stacked_preds[i])\n",
        "                max_votes = torch.max(vote_counts)\n",
        "                candidates = torch.where(vote_counts == max_votes)[0]\n",
        "                if len(candidates) > 1:\n",
        "                    predictions[i] = predicted_fusion[i]  # Prioritize fused classifier in case of a tie\n",
        "                else:\n",
        "                    predictions[i] = candidates[0]\n",
        "\n",
        "            predictions_all.extend(predictions.tolist())\n",
        "\n",
        "            total += batch_size\n",
        "            correct += (predictions == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy, predictions_all\n",
        "\n",
        "# List of your already trained models\n",
        "models = [model1, model2, model3, model_fusion]\n",
        "\n",
        "# Perform majority voting\n",
        "accuracy_majority_voting_fusion, _ = majority_voting(models, test_loader_fused)\n",
        "\n",
        "print('Accuracy with low and high level image fusion:', accuracy_majority_voting_fusion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "e66d7vFc0k7h",
        "outputId": "6e47535e-244b-4f54-d86e-4cee3c4c660b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGwCAYAAACHJU4LAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVBpJREFUeJzt3XlcTfn/B/DXbbvtRVSiomkhhLLF2CPLWL4M3zHNiK9lZmQX8bNmxGCMZSaZL6YwiLE0tmFMY82WjDCT0GSKUpRKaFHn94dxv+4Uurrde5xez3mcx6P7OZ/zOe97MvXu/fmcc2WCIAggIiIiEiEdbQdARERE9DJMVIiIiEi0mKgQERGRaDFRISIiItFiokJERESixUSFiIiIRIuJChEREYmWnrYDoFcrLS1FWloazMzMIJPJtB0OERGpQBAEPHz4EHZ2dtDRqbraQEFBAYqKitQyloGBAQwNDdUyljowURG5tLQ02NvbazsMIiKqhNTUVNSrV69Kxi4oKICRmRXw9LFaxrO1tUVycrJokhUmKiJnZmYGAOi0cC/0DE20HE31sGJgE22HUO1k56vnL0GqmEZ1zbUdQrXxMC8Pzg3sFT/Lq0JRURHw9DHk7v6ArkHlBispwt0/NqKoqIiJClXM8+kePUMT6BkxUdEEMzP+ENe0IhkTFU0yN+e/cU3TyNS9niFklUxUBJn4lq4yUSEiIpICGYDKJkQiXAopvtSJiIiIVCfTUc9WQfPnz4dMJlPaGjZsqNhfUFCAgIAAWFlZwdTUFIMGDUJGRobKb4uJChEREb2Rxo0bIz09XbGdOnVKsW/y5MnYt28ffvjhBxw/fhxpaWkYOHCgyufg1A8REZEUyGRqmPp5dnxeXp5Ss1wuh1wuL9NdT08Ptra2Zdpzc3OxYcMGbN26FV27dgUAhIeHo1GjRjh79izatm1b4ZBYUSEiIpICNU792Nvbw8LCQrEtXry43FPeuHEDdnZ2cHJygp+fH1JSUgAAcXFxKC4uho+Pj6Jvw4YN4eDggDNnzqj0tlhRISIiIiWpqalKd4eVV01p06YNIiIi4ObmhvT0dAQHB6NDhw64evUq7t69CwMDA1haWiodY2Njg7t376oUCxMVIiIiKVDj1I+5uflrb2Pv1auX4msPDw+0adMGjo6O2LFjB4yMjCoXxws49UNERCQJ6pj2efO0wNLSEq6urrh58yZsbW1RVFSEnJwcpT4ZGRnlrml5zbsiIiIiqpz8/HwkJSWhTp068PLygr6+PqKjoxX7ExMTkZKSAm9vb5XG5dQPERGRFKhx6qciAgMD0bdvXzg6OiItLQ3z5s2Drq4uhg4dCgsLC4wcORJTpkxBzZo1YW5ujvHjx8Pb21ulO34AJipERETSoOID2146RgXdvn0bQ4cORVZWFmrXro13330XZ8+eRe3atQEAK1asgI6ODgYNGoTCwkL4+vpizZo1KofERIWIiIhUFhkZ+cr9hoaGCA0NRWhoaKXOw0SFiIhICjQ89aMpTFSIiIikQMNTP5rCRIWIiEgKJFpREV/qRERERPQ3VlSIiIikgFM/REREJFoymRoSFU79EBEREVUYKypERERSoCN7tlV2DJFhokJERCQFEl2jIr6IiIiIiP7GigoREZEUSPQ5KkxUiIiIpIBTP0RERESaxYoKERGRFHDqh4iIiERLolM/TFSIiIikQKIVFfGlTkRERER/Y0WFiIhICjj1Q0RERKLFqR8iIiIizWJFhYiISBLUMPUjwvoFExUiIiIp4NQPERERkWaxokJERCQFMpka7voRX0WFiQoREZEUSPT2ZPFFRERERPQ3VlTojfVsZI2e7jawNpMDAFIePMaOi3dwMTUXANCjYW10dK4Fp1omMDbQhV/EBTwqKtFmyJKUcT8Xy9cfwInz11BQWAQHu1pYFPhvNHGz13Zob71Lvydja9RJJCbdQdaDh1g04yN0bOOu2H/8zFVEHT6PxKQ7yMt/gvCvxsGlgZ0WI5audTuO4+vvo5GZlYcmLnWxZNpgeDWur+2wxIWLaaVPJpMhKipK62O8LbIeFWHz+RRM3X0FgXuu4kpaHmb2cIV9DSMAgFxPFxdTc7DztztajlS6ch8+xoeTvoGerg7+u2gU9q+fhqBP+sLczEjboUnCk4IiONe3xZQx/crfX1gMj0aO+GxYTw1HVr3s/jkOs1fuQdCoXji2OQhNXOpi0PhQ3Mt+qO3QxOX51E9lN5GpVhWVu3fvIiQkBAcOHMCdO3dgbW2N5s2bY9KkSejWrRvS09NRo0YNbYf51ohNyVF6vSX2Nno2soGbtSlSHzzBvqt3AQBN6phpIbrqYf32o6hT2xKLpn2gaKtXx0qLEUmLt5cbvL3cXrq/Z+cWAID0zAeaCqlaWrP1Vwwb0A5+/bwBAF/N/AA/x/yO7/eeweThPbQcnYhItKJSbRKVW7duoX379rC0tMSyZcvQtGlTFBcX4/DhwwgICMC1a9dga2v7yjGKi4uhr6+voYjfLjoyoJ1TTRjq6+BaRr62w6k2jp75He1bumHSgk2IvZIEGysLfNCvHYb0bqvt0IjUoqj4KS5dS1VKSHR0dNCptRtiryRrMTLSFPHVeKrI2LFjIZPJcP78eQwaNAiurq5o3LgxpkyZgrNnzwJQnra5desWZDIZtm/fjk6dOsHQ0BBbtmwBAHz33Xdo3Lgx5HI56tSpg3Hjxr30vKmpqRgyZAgsLS1Rs2ZN9O/fH7du3Xpp/8LCQuTl5SltYuZYwwjbRrTEDyNb47N3G+CLn6/jds4TbYdVbaSmZyNy3xk41q2FdYvH4IO+7bAoNApRP8dqOzQitcjKyUdJSSlq11SuzNauaY7MLHH/fNQ4iU79iC+iKpCdnY1Dhw4hICAAJiYmZfZbWlq+9NgZM2Zg4sSJSEhIgK+vL8LCwhAQEIAxY8bgypUr2Lt3L5ydncs9tri4GL6+vjAzM8PJkycRExMDU1NT9OzZE0VFReUes3jxYlhYWCg2e3txL4i8k1uAybuuYHrUVfz0RyYmdH4H9Sy5PkJTBEGAu0tdTB7ZG+7OdTGkT1sM7t0WkfvPajs0ItK051M/ld1EplpM/dy8eROCIKBhw4YqHztp0iQMHDhQ8XrhwoWYOnUqJk6cqGhr1apVucdu374dpaWlWL9+PWR/f/PDw8NhaWmJY8eOoUePsnOrM2fOxJQpUxSv8/LyRJ2sPC0VcDevEACQdP8xXGqboG9TG4SdvKXdwKqJWjXN8I6DjVKbk4M1fj55WUsREamXlaUpdHV1yiycvZedB2srcy1FRZpULRIVQRDe+NiWLVsqvs7MzERaWhq6detWoWPj4+Nx8+ZNmJkplywLCgqQlJRU7jFyuRxyufyN49U2mQzQ16kWhTpR8GzcALdu31Nqu3X7HuxsuCicpMFAXw/NG9rjeGwi+nRuBgAoLS3FidjrGDW4o5ajExeZTKb4o7gSg6gnGDWqFomKi4sLZDIZrl27pvKxL04VGRmpNqWRn58PLy8vxdqWF9WuXVvlWMTmo1b2uJiag/v5hTDS10UH51poYmeO4IPPrrOlkT5qGOvD1twQAOBY0xhPiktwL78Q+YV8noo6+A/qgA8nfoNvt0ajZ6dmuJKYgh8OnkXwpMHaDk0SHj8pxJ27WYrX6RnZuJGcBjNTY9jWtkTew8fIuJ+D+3//tZ9y5z4AoKalGaxq8G43dRn7YVeMDd6MFo0c4Nm4PsK2HcWjJ4Xw68tF4y9iovIWq1mzJnx9fREaGooJEyaUWaeSk5PzynUqz5mZmaF+/fqIjo5Gly5dXtvf09MT27dvh7W1NczNpVeitDTSw6Qu76CGsT4eFZXgr6zHCD54DfF3ni1w6+lujQ+86in6L+r37EFZq48l4dfr97USs9Q0dXPA6vnDsWLDQaz5/gjq2dbEjM/6o283T22HJgnXku5gwpz1itdfhx8EAPTq4olZE97HqdgELPp6l2L/vOWRAIAR/+6KkR/4aDZYCRvYwwv3c/Kx6NsDyMx6iKaudbFzdQCnfqqJapGoAEBoaCjat2+P1q1bY8GCBfDw8MDTp09x5MgRhIWFISEhoULjzJ8/H59++imsra3Rq1cvPHz4EDExMRg/fnyZvn5+fli2bBn69++PBQsWoF69evjrr7+we/duTJ8+HfXq1SvnDG+Pb068+tbAyLg7iIzjw96qWpe27ujS1v31HUllnk2ccGrPopfu793VC727emkwouprzJBOGDOkk7bDEDfZ31tlxxCZapOoODk54eLFiwgJCcHUqVORnp6O2rVrw8vLC2FhYRUex9/fHwUFBVixYgUCAwNRq1YtvP/+++X2NTY2xokTJxAUFISBAwfi4cOHqFu3Lrp16ybJCgsREWmPVKd+ZEJlVppSlcvLy4OFhQW6fRkNPaOyt1aT+q0d0kzbIVQ7Wfnl365PVaNxPf6hpCl5eXmwsbJAbm5ulf2B+vz3hPGANZDpV+7xEELxEzyOGlul8aqq2lRUiIiIpEyqFRUmKkRERBLARIWIiIhES6qJCp/MRURERKLFigoREZEU8PZkIiIiEitO/RARERFpGCsqREREEiCTQQ0VFfXEok5MVIiIiCRABjVM/YgwU+HUDxEREYkWKypEREQSINXFtExUiIiIpECitydz6oeIiIhEixUVIiIiKVDD1I/AqR8iIiKqCupYo1L5u4bUj4kKERGRBEg1UeEaFSIiIhItVlSIiIikQKJ3/TBRISIikgBO/RARERFpGCsqREREEiDVigoTFSIiIgmQaqLCqR8iIiKqtC+++AIymQyTJk1StBUUFCAgIABWVlYwNTXFoEGDkJGRodK4TFSIiIgk4HlFpbLbm4iNjcW3334LDw8PpfbJkydj3759+OGHH3D8+HGkpaVh4MCBKo3NRIWIiEgKZGraVJSfnw8/Pz+sW7cONWrUULTn5uZiw4YN+Oqrr9C1a1d4eXkhPDwcp0+fxtmzZys8PhMVIiIiUpKXl6e0FRYWvrRvQEAA+vTpAx8fH6X2uLg4FBcXK7U3bNgQDg4OOHPmTIVjYaJCREQkAeqc+rG3t4eFhYViW7x4cbnnjIyMxMWLF8vdf/fuXRgYGMDS0lKp3cbGBnfv3q3w++JdP0RERBKgzrt+UlNTYW5urmiXy+Vl+qampmLixIk4cuQIDA0NK3XeV2FFhYiISALUWVExNzdX2spLVOLi4pCZmQlPT0/o6elBT08Px48fx+rVq6GnpwcbGxsUFRUhJydH6biMjAzY2tpW+H2xokJEREQq69atG65cuaLUNmLECDRs2BBBQUGwt7eHvr4+oqOjMWjQIABAYmIiUlJS4O3tXeHzMFEhIiKSAg1/KKGZmRmaNGmi1GZiYgIrKytF+8iRIzFlyhTUrFkT5ubmGD9+PLy9vdG2bdsKn4eJChERkQSI8cm0K1asgI6ODgYNGoTCwkL4+vpizZo1Ko3BRIWIiIjU4tixY0qvDQ0NERoaitDQ0Dcek4kKERGRBIixoqIOTFSIiIgkQAY1JCqVXuSifrw9mYiIiESLFRUiIiIJ4NQPERERiZeGb0/WFCYqb4nv/FooPc6Yqk6d/su1HUK1c29/oLZDICKRYqJCREQkAZz6ISIiItFiokJERESiJZM92yo7htjw9mQiIiISLVZUiIiIJOBZRaWyUz9qCkaNmKgQERFJgRqmfsR4ezKnfoiIiEi0WFEhIiKSAN71Q0RERKLFu36IiIiINIwVFSIiIgnQ0ZFBR6dyJRGhksdXBSYqREREEsCpHyIiIiINY0WFiIhIAnjXDxEREYmWVKd+mKgQERFJgFQrKlyjQkRERKLFigoREZEESLWiwkSFiIhIAqS6RoVTP0RERCRarKgQERFJgAxqmPqB+EoqTFSIiIgkgFM/RERERBrGigoREZEE8K4fIiIiEi1O/RARERFpGCsqREREEsCpHyIiIhItqU79MFEhIiKSAKlWVLhGhYiIiESLFRUiIiIpUMPUjwgfTMtEhYiISAo49UNERESkYayoEBERSQDv+iEiIiLR4tQPERERkYaxokJERCQBnPohIiIi0eLUDxEREZGGsaJCREQkAVKtqDBRISIikgCuUSF6jdWbjuDg8Xjc/CsThnJ9tGzaALM/6wtnRxtthyZJkwa3wbz/dEJY1AX837e/wt7aHJc3flpu3+EhP+LHU4kajlCaTv92E6HfRyM+MRUZ9/Owccko9O7koe2wJG/djuP4+vtoZGbloYlLXSyZNhhejetrOyxRkWpF5a1fo3Lv3j189tlncHBwgFwuh62tLXx9fRETE6Pt0KqdM5duYsTADjjw38nYvnIsnj4twQeTw/D4SaG2Q5OcFq62GN67Ga7+malou3P/Idw+DFXaFm0+hYePi/DLhT+1GK20PH5ShMYudbEkcLC2Q6k2dv8ch9kr9yBoVC8c2xyEJi51MWh8KO5lP9R2aKQBb31FZdCgQSgqKsLGjRvh5OSEjIwMREdHIysrS6txFRUVwcDAQKsxaNq2rz5Ter1ylh+avjcL8Ymp8G7urKWopMfEUB//nfYeJq46jMCh3or20lIBmQ8eKfV9r50Lok5ew6OCYk2HKVk+7dzh085d22FUK2u2/ophA9rBr9+zf+9fzfwAP8f8ju/3nsHk4T20HJ14SHXq562uqOTk5ODkyZNYsmQJunTpAkdHR7Ru3RozZ85Ev379AAA3btxAx44dYWhoCHd3dxw5cgQymQxRUVEAgGPHjkEmkyEnJ0cx7qVLlyCTyXDr1i0AQFZWFoYOHYq6devC2NgYTZs2xbZt25Ri6dy5M8aNG4dJkyahVq1a8PX1BQBcvXoVvXr1gqmpKWxsbPDxxx/j/v37VX5txODhoycAgBrmxlqORFqWBXTHz7F/4vilv17Zr5mzDTzescH3hy9rKDIi9SsqfopL11LRubWbok1HRwedWrsh9kqyFiMTn+dTP5XdxOatTlRMTU1hamqKqKgoFBaWnV4oLS3FwIEDYWBggHPnzmHt2rUICgpS+TwFBQXw8vLCgQMHcPXqVYwZMwYff/wxzp8/r9Rv48aNMDAwQExMDNauXYucnBx07doVLVq0wIULF3Do0CFkZGRgyJAhLz1XYWEh8vLylLa3UWlpKeau2o1WHg3Q0MlO2+FIxsBODdHsHRssCD/+2r4f+3rgWsp9nE9I00BkRFUjKycfJSWlqF3TTKm9dk1zZGa9nT8fSTVv9dSPnp4eIiIiMHr0aKxduxaenp7o1KkTPvjgA3h4eOCXX37BtWvXcPjwYdjZPftluWjRIvTq1Uul89StWxeBgYGK1+PHj8fhw4exY8cOtG7dWtHu4uKCpUuXKl4vXLgQLVq0wKJFixRt3333Hezt7XH9+nW4urqWOdfixYsRHBysUnxiNHP5Tlz78y5+DJuo7VAko24tMyz+pBsG/t8OFBaXvLKvoYEe3u/cCMu2ndFQdESkbTKoYepHLZGo11udqADP1qj06dMHJ0+exNmzZ/HTTz9h6dKlWL9+PXJzc2Fvb69IUgDA29v7FaOVr6SkBIsWLcKOHTtw584dFBUVobCwEMbGylMaXl5eSq/j4+Nx9OhRmJqalhkzKSmp3ERl5syZmDJliuJ1Xl4e7O3tVY5Zm/5v+U78cvp37AmdADtrS22HIxnNXGxgXcMEx77xV7Tp6eqgXRN7jO7rCZt+y1FaKgAA+r/rCiO5PiKjr2orXCK1sLI0ha6uTpmFs/ey82BtZa6lqMRJRyaDTiUzlcoeXxXe+kQFAAwNDdG9e3d0794dc+bMwahRozBv3jylX/gvo6PzbPZLEARFW3Gx8sLDZcuWYdWqVVi5ciWaNm0KExMTTJo0CUVFRUr9TExMlF7n5+ejb9++WLJkSZnz1qlTp9x45HI55HL5a+MWI0EQMOurXfjpxGXs+mYcHOystB2SpJy4lIJ2n36n1PbNlF64kZqNVT+cUyQpAPCRrwd+OncTWblPNB0mkVoZ6OuheUN7HI9NRJ/OzQA8m1o+EXsdowZ31HJ0pAmSSFT+yd3dHVFRUWjUqBFSU1ORnp6uSAzOnj2r1Ld27doAgPT0dNSoUQPAs8W0L4qJiUH//v3x0UcfAXj2P8n169fh7v7qlf+enp7YtWsX6tevDz09SV5qJTOX/4A9Ry4i/ItRMDU2VMwfm5kawkheve6Aqgr5T4qQ8JfyQuzHBcXIfvhEqb1BHUu0a2KPIXN3ajrEaiH/cSGSb99TvE5Jy8KV67dRw9wY9WxrajEy6Rr7YVeMDd6MFo0c4Nm4PsK2HcWjJ4Xw69tW26GJilTv+nmrf3tmZWVh8ODB+M9//gMPDw+YmZnhwoULWLp0Kfr37w8fHx+4urrC398fy5YtQ15eHmbNmqU0hrOzM+zt7TF//nyEhITg+vXrWL58uVIfFxcX7Ny5E6dPn0aNGjXw1VdfISMj47WJSkBAANatW4ehQ4di+vTpqFmzJm7evInIyEisX78eurq6ar8m2rRxz7Nn1wwa97VS+8r/+xD/7tNGGyFVSx/1aIq0+w/x60XeEVEV4hNSMCDgf//G56zaAwD4d+/W+GbuR9oKS9IG9vDC/Zx8LPr2ADKzHqKpa13sXB3AqZ9/kOoD397qRMXU1BRt2rTBihUrkJSUhOLiYtjb22P06NH4v//7P+jo6GDPnj0YOXIkWrdujfr162P16tXo2bOnYgx9fX1s27YNn332GTw8PNCqVSssXLgQgwf/72FOs2fPxp9//glfX18YGxtjzJgxGDBgAHJzc18Zn52dHWJiYhAUFIQePXqgsLAQjo6O6Nmzp2LKSUrSY1ZpO4Rqp29QZJm2zzeexOcbT2ohmuqhvZcL7p1dre0wqp0xQzphzJBO2g5D1HRkz7bKjiE2MuHFxRnVhEwmw549ezBgwABth/JaeXl5sLCwwF/p2TA3518PmlCn//LXdyK1urc/8PWdSG30dKX3h5JY5eXlwcbKArm5uVX2M/z57wmf5dHQMzJ5/QGv8PTJI/wytVuVxquqt7qiQkRERH+TqWHqRoQVFSYqREREEsDFtBJSDWe7iIiI3kqcqCQiIpIAmZr+q6iwsDB4eHjA3Nwc5ubm8Pb2xk8//aTYX1BQgICAAFhZWcHU1BSDBg1CRkaGyu+LiQoREZEEPL/rp7JbRdWrVw9ffPEF4uLicOHCBXTt2hX9+/fH77//DgCYPHky9u3bhx9++AHHjx9HWloaBg4cqPL7qpZTP0RERPRy//xA3PKemt63b1+l1yEhIQgLC8PZs2dRr149bNiwAVu3bkXXrl0BAOHh4WjUqBHOnj2Ltm0r/rA+VlSIiIgk4PkD3yq7AYC9vT0sLCwU2+LFi1957pKSEkRGRuLRo0fw9vZGXFwciouL4ePjo+jTsGFDODg44MwZ1T4slRUVIiIiCVDnXT+pqalKz1F52WfQXblyBd7e3igoKICpqSn27NkDd3d3XLp0CQYGBrC0tFTqb2Njg7t376oUU4USlb1791Z4wH79+qkUABEREYnL8wWyr+Pm5oZLly4hNzcXO3fuhL+/P44fP67WWCqUqFT0Ca4ymQwlJSWViYeIiIjegI5MBp1KllRUPd7AwADOzs4AAC8vL8TGxmLVqlX497//jaKiIuTk5ChVVTIyMmBra6taTBXpVFpaWqGNSQoREZF2PJ/6qexWGaWlpSgsLISXlxf09fURHR2t2JeYmIiUlBR4e3urNGal1qgUFBTA0NCwMkMQERGRGmj605NnzpyJXr16wcHBAQ8fPsTWrVtx7NgxHD58GBYWFhg5ciSmTJmCmjVrwtzcHOPHj4e3t7dKd/wAb3DXT0lJCT7//HPUrVsXpqam+PPPPwEAc+bMwYYNG1QdjoiIiN5CmZmZGDZsGNzc3NCtWzfExsbi8OHD6N69OwBgxYoVeO+99zBo0CB07NgRtra22L17t8rnUbmiEhISgo0bN2Lp0qUYPXq0or1JkyZYuXIlRo4cqXIQREREVDma/qyf1xUnDA0NERoaitDQ0ErFpHJFZdOmTfjvf/8LPz8/6OrqKtqbNWuGa9euVSoYIiIiejPPF9NWdhMblROVO3fuKFb4vqi0tBTFxcVqCYqIiIgIeINExd3dHSdPnizTvnPnTrRo0UItQREREZFqZGraxEblNSpz586Fv78/7ty5g9LSUuzevRuJiYnYtGkT9u/fXxUxEhER0Wto+q4fTVG5otK/f3/s27cPv/zyC0xMTDB37lwkJCRg3759ipW+REREROrwRs9R6dChA44cOaLuWIiIiOgN6ciebZUdQ2ze+IFvFy5cQEJCAoBn61a8vLzUFhQRERGpRqpTPyonKrdv38bQoUMRExOjeH5/Tk4O2rVrh8jISNSrV0/dMRIREVE1pfIalVGjRqG4uBgJCQnIzs5GdnY2EhISUFpailGjRlVFjERERFQB2vycn6qickXl+PHjOH36NNzc3BRtbm5u+Prrr9GhQwe1BkdEREQVw6mfv9nb25f7YLeSkhLY2dmpJSgiIiJSjVQX06o89bNs2TKMHz8eFy5cULRduHABEydOxJdffqnW4IiIiKh6q1BFpUaNGkrloEePHqFNmzbQ03t2+NOnT6Gnp4f//Oc/GDBgQJUESkRERC9Xrad+Vq5cWcVhEBERUWWo4xH44ktTKpio+Pv7V3UcRERERGW88QPfAKCgoABFRUVKbebm5pUKiIiIiFSnI5NBp5JTN5U9viqovJj20aNHGDduHKytrWFiYoIaNWoobURERKR5lX2GilifpaJyojJ9+nT8+uuvCAsLg1wux/r16xEcHAw7Ozts2rSpKmIkIiKiakrlqZ99+/Zh06ZN6Ny5M0aMGIEOHTrA2dkZjo6O2LJlC/z8/KoiTiIiInoFqd71o3JFJTs7G05OTgCerUfJzs4GALz77rs4ceKEeqMjIiKiCuHUz9+cnJyQnJwMAGjYsCF27NgB4Fml5fmHFBIRERGpg8qJyogRIxAfHw8AmDFjBkJDQ2FoaIjJkydj2rRpag+QiIiIXu/5XT+V3cRG5TUqkydPVnzt4+ODa9euIS4uDs7OzvDw8FBrcERERFQx6pi6EWGeUrnnqACAo6MjHB0d1RELERERvSGpLqatUKKyevXqCg84YcKENw6GiIiI6EUVSlRWrFhRocFkMhkTlSpSWFyCguISbYdRLaTumaLtEKqd2m35c0OTHsR+o+0QqAro4A0WnpYzhthUKFF5fpcPERERiZNUp37EmDwRERERAVDDYloiIiLSPpkM0OFdP0RERCRGOmpIVCp7fFXg1A8RERGJFisqREREEsDFtC84efIkPvroI3h7e+POnTsAgM2bN+PUqVNqDY6IiIgq5vnUT2U3sVE5Udm1axd8fX1hZGSE3377DYWFhQCA3NxcLFq0SO0BEhERUfWlcqKycOFCrF27FuvWrYO+vr6ivX379rh48aJagyMiIqKKef5ZP5XdxEblNSqJiYno2LFjmXYLCwvk5OSoIyYiIiJSkTo+/ViMn56sckXF1tYWN2/eLNN+6tQpODk5qSUoIiIiUo2OmjaxUTmm0aNHY+LEiTh37hxkMhnS0tKwZcsWBAYG4rPPPquKGImIiKiaUnnqZ8aMGSgtLUW3bt3w+PFjdOzYEXK5HIGBgRg/fnxVxEhERESvoY41JiKc+VE9UZHJZJg1axamTZuGmzdvIj8/H+7u7jA1Na2K+IiIiKgCdKCGNSoQX6byxg98MzAwgLu7uzpjISIiIlKicqLSpUuXVz657tdff61UQERERKQ6Tv38rXnz5kqvi4uLcenSJVy9ehX+/v7qiouIiIhUINUPJVQ5UVmxYkW57fPnz0d+fn6lAyIiIiJ6Tm23TH/00Uf47rvv1DUcERERqUAm+99D3950k8TUz8ucOXMGhoaG6hqOiIiIVMA1Kn8bOHCg0mtBEJCeno4LFy5gzpw5aguMiIiISOVExcLCQum1jo4O3NzcsGDBAvTo0UNtgREREVHFcTEtgJKSEowYMQJNmzZFjRo1qiomIiIiUpHs7/8qO4bYqLSYVldXFz169OCnJBMREYnM84pKZTexUfmunyZNmuDPP/+siliIiIiIlKicqCxcuBCBgYHYv38/0tPTkZeXp7QRERGR5km1olLhNSoLFizA1KlT0bt3bwBAv379lB6lLwgCZDIZSkpK1B8lERERvZJMJnvlR9xUdAyxqXCiEhwcjE8//RRHjx6tyniIiIiIFCqcqAiCAADo1KlTlQVDREREb4a3J0OcJSEiIiLik2kBAK6urq9NVrKzsysVEBEREdFzKiUqwcHBZZ5MS0RERNr3/IMFKzuG2KiUqHzwwQewtrauqliIiIjoDUl1jUqFn6PC9SlERESkaSrf9UNEREQipIbFtCL8qJ+KV1RKS0s57UNERCRSOpCpZauoxYsXo1WrVjAzM4O1tTUGDBiAxMREpT4FBQUICAiAlZUVTE1NMWjQIGRkZKj4voiIiOit9/z25MpuFXX8+HEEBATg7NmzOHLkCIqLi9GjRw88evRI0Wfy5MnYt28ffvjhBxw/fhxpaWkYOHCgSu9LpcW0RERERABw6NAhpdcRERGwtrZGXFwcOnbsiNzcXGzYsAFbt25F165dAQDh4eFo1KgRzp49i7Zt21boPKyoEBERSYA6P5Twnx84XFhY+Nrz5+bmAgBq1qwJAIiLi0NxcTF8fHwUfRo2bAgHBwecOXOm4u9LhWtAREREIvX8OSqV3QDA3t4eFhYWim3x4sWvPHdpaSkmTZqE9u3bo0mTJgCAu3fvwsDAAJaWlkp9bWxscPfu3Qq/L079UJUJ2xKNpesOYMSgDpg7/l/aDkeSNu05hc1RMbh999kToV0b2GLScF90aeuu5cikIWh0b8wY01up7fqtu2gzeCEAwP9f7fG+b0t4uNWDuakRHLtMQ17+E22EKnnrdhzH199HIzMrD01c6mLJtMHwalxf22FJVmpqKszNzRWv5XL5K/sHBATg6tWrOHXqlNpjkWRFZf78+WjevLnGzxsREVEmc6yu4q+lYOu+M2j4Th1thyJpdawtMfPTvji4PhAH1k1FO09XjJy5AYnJ6doOTTISktLg1nOmYus1aoVin5GhPqLP/IEVET9rMULp2/1zHGav3IOgUb1wbHMQmrjUxaDxobiX/VDboYmKOhfTmpubK22vSlTGjRuH/fv34+jRo6hXr56i3dbWFkVFRcjJyVHqn5GRAVtb2wq/L9EnKjKZ7JXb/PnzyxwTGBiI6OhozQdLAIBHjwsxaeEWLA4cAgtTY22HI2nd2zdBV293NLCvDScHawSN6QNjIzl++/0vbYcmGU9LSpGZ9VCxZef+746GtduOYeXGI4i9ckt7AVYDa7b+imED2sGvnzcaOtXBVzM/gLGhAb7fW/F1DtWBDtQw9aPC7cmCIGDcuHHYs2cPfv31VzRo0EBpv5eXF/T19ZV+HycmJiIlJQXe3t4VPo/op37S0//3l+H27dsxd+5cpfu0TU1NFV8LgoCSkhKYmpoqtZNmzV21C13bNsK7LV3xzeYj2g6n2igpKcX+o5fwpKAQniyJq42TfW38cTAEhUXFiL2SjAXf7MXtjAfaDqvaKCp+ikvXUjF5eA9Fm46ODjq1dkPslWQtRkYBAQHYunUrfvzxR5iZmSnWnVhYWMDIyAgWFhYYOXIkpkyZgpo1a8Lc3Bzjx4+Ht7d3he/4Ad6Cioqtra1is7CwgEwmU7y+du0azMzM8NNPP8HLywtyuRynTp0qM/UTGxuL7t27o1atWrCwsECnTp1w8eJFpfPIZDKsX78e//rXv2BsbAwXFxfs3btXqc/evXvh4uICQ0NDdOnSBRs3boRMJitT1nrRjz/+CE9PTxgaGsLJyQnBwcF4+vTpS/sXFhaWWW39NtkX/Rt+v34b00f30XYo1UZCUhrcekzHO90C8X/Ld2BdyEi4Nqh4WZVeLu73WwgI/h6DJ4Ri6hfb4WhnhYPrJsPU+NXz9aQ+WTn5KCkpRe2aZkrttWuaIzPr7fr5WNU0/RyVsLAw5ObmonPnzqhTp45i2759u6LPihUr8N5772HQoEHo2LEjbG1tsXv3bpXel+gTlYqYMWMGvvjiCyQkJMDDw6PM/ocPH8Lf3x+nTp3C2bNn4eLigt69e+PhQ+X5zeDgYAwZMgSXL19G79694efnh+zsZ4sUk5OT8f7772PAgAGIj4/HJ598glmzZr0yrpMnT2LYsGGYOHEi/vjjD3z77beIiIhASEjIS49ZvHix0kpre3v7N7gi2pGW+QDB3+zBitkfQS7X13Y41cY7DtY49N007P12Mj7u3x6TQ7bgenLFV9TTy/1y+g/8GP0bfr+Zhl/PJmDwxDBYmBlhgI+ntkMjKkNHTVtFCYJQ7jZ8+HBFH0NDQ4SGhiI7OxuPHj3C7t27VVqfArwFUz8VsWDBAnTv3v2l+58/aOa5//73v7C0tMTx48fx3nvvKdqHDx+OoUOHAgAWLVqE1atX4/z58+jZsye+/fZbuLm5YdmyZQAANzc3XL169ZVJR3BwMGbMmAF/f38AgJOTEz7//HNMnz4d8+bNK/eYmTNnYsqUKYrXeXl5b02ycjXxNrIe5KPv6K8UbSWlpTh/+U9s2hODxCNLoasridxYVAz09dCgXm0AgIebPeKvpeK7ncfxxbR/azky6cnLf4KbKZlwsq+t7VCqDStLU+jq6pRZOHsvOw/WVuYvOYqkRBKJSsuWLV+5PyMjA7Nnz8axY8eQmZmJkpISPH78GCkpKUr9XqzGmJiYwNzcHJmZmQCeLQBq1aqVUv/WrVu/8rzx8fGIiYlRSmZKSkpQUFCAx48fw9i47EJTuVz+2tvAxKqdlwsOfTdNqW36kkg4OVjj06FdmaRoSKkgoLDo5dOL9OZMjAzQoG4tbL9/XtuhVBsG+npo3tAex2MT0adzMwDPntlxIvY6Rg3uqOXoxOX5TSaVHUNsJJGomJiYvHK/v78/srKysGrVKjg6OkIul8Pb2xtFRUVK/fT1lacrZDIZSktL3ziu/Px8BAcHl/u5BoaGhm88rliZGhvCzUn5dmQjQwPUMDcu007q8cXafejc1h11bSyR/7gQPx6Jw5nfbuL75Z9qOzRJWDDxXzh08gpS07NRp7YFZozpg5LSUuw6HAcAsLYyg7WVOZzsawEAGjvb4eHjAty++wA5eY+1GbqkjP2wK8YGb0aLRg7wbFwfYduO4tGTQvj1rfiCzOpAhsp/+LH40hSJJCqvExMTgzVr1qB372cPbkpNTcX9+/dVGsPNzQ0HDx5UaouNjX3lMZ6enkhMTISzs7NqARNV0P2cfEwO+R6ZWXkwMzFCo3fs8P3yT9GxlZu2Q5OEutaWWL9wBGpaGOP+g3yci/8T3UcsR1ZOPgBgxMAOSg+EO7huMgBgbPBmbNt/TisxS9HAHl64n5OPRd8eQGbWQzR1rYudqwM49fMPLz5ZtjJjiE21SFRcXFywefNmtGzZEnl5eZg2bRqMjIxUGuOTTz7BV199haCgIIwcORKXLl1CREQEgJeXyubOnYv33nsPDg4OeP/996Gjo4P4+HhcvXoVCxcurOzbeitErgrQdgiS9uWModoOQdJGzgp/5f4l6w5iybqDr+xD6jFmSCeMGdJJ22GQFlSLRQMbNmzAgwcP4OnpiY8//hgTJkyAtbW1SmM0aNAAO3fuxO7du+Hh4YGwsDDFXT8vW1Pi6+uL/fv34+eff0arVq3Qtm1brFixAo6OjpV+T0RERP8kq+QmRjJBEARtB/G2CgkJwdq1a5Gamlpl58jLy4OFhQWup9yDmTnLnJqgx0W/GmffYZK2Q6hWHsR+o+0Qqo28vDzYWFkgNzdX6bNz1H0OCwsLrDv+B4xNzV5/wCs8zn+I0Z3cqzReVVWLqR91WbNmDVq1agUrKyvExMRg2bJlGDdunLbDIiIikiwmKiq4ceMGFi5ciOzsbDg4OGDq1KmYOXOmtsMiIiLi7cn07FHAK1aseH1HIiIiDVP1ybIvG0NsxBgTEREREQBWVIiIiCSBUz9EREQkWlJ9Mi2nfoiIiEi0WFEhIiKSAE79EBERkWhJ9a4fJipEREQSINWKihiTJyIiIiIArKgQERFJglTv+mGiQkREJAEy2bOtsmOIDad+iIiISLRYUSEiIpIAHcigU8nJm8oeXxWYqBAREUkAp36IiIiINIwVFSIiIgmQ/f1fZccQGyYqREREEsCpHyIiIiINY0WFiIhIAmRquOuHUz9ERERUJaQ69cNEhYiISAKkmqhwjQoRERGJFisqREREEsDbk4mIiEi0dGTPtsqOITac+iEiIiLRYkWFiIhIAjj1Q0RERKLFu36IiIiINIwVFSIiIgmQofJTNyIsqDBRISIikgLe9UNERESkYayoEBERSQDv+iEiIiLRkupdP0xUiIiIJECGyi+GFWGewjUqREREJF6sqBAREUmADmTQqeTcjY4IaypMVN4SFiYGMDcx0HYYRFXiQew32g6hWrEaGq7tEKoNofiJxs7FqR8iIiIiDWNFhYiISAokWlJhokJERCQBUn2OCqd+iIiISLRYUSEiIpICNTzwTYQFFSYqREREUiDRJSqc+iEiIiLxYkWFiIhICiRaUmGiQkREJAFSveuHiQoREZEESPXTk7lGhYiIiESLFRUiIiIJkOgSFSYqREREkiDRTIVTP0RERCRarKgQERFJAO/6ISIiItHiXT9ERERELzhx4gT69u0LOzs7yGQyREVFKe0XBAFz585FnTp1YGRkBB8fH9y4cUOlczBRISIikgCZmjZVPHr0CM2aNUNoaGi5+5cuXYrVq1dj7dq1OHfuHExMTODr64uCgoIKn4NTP0RERFKgxrt+8vLylJrlcjnkcnmZ7r169UKvXr3KHUoQBKxcuRKzZ89G//79AQCbNm2CjY0NoqKi8MEHH1QoJFZUiIiISIm9vT0sLCwU2+LFi1UeIzk5GXfv3oWPj4+izcLCAm3atMGZM2cqPA4rKkRERBKgzrt+UlNTYW5urmgvr5ryOnfv3gUA2NjYKLXb2Ngo9lUEExUiIiIJUOddP+bm5kqJijZx6oeIiEgCtLGY9lVsbW0BABkZGUrtGRkZin0VwUSFiIiI1K5BgwawtbVFdHS0oi0vLw/nzp2Dt7d3hcfh1A8REZEUaOGzfvLz83Hz5k3F6+TkZFy6dAk1a9aEg4MDJk2ahIULF8LFxQUNGjTAnDlzYGdnhwEDBlT4HExUiIiIJEAbj9C/cOECunTpong9ZcoUAIC/vz8iIiIwffp0PHr0CGPGjEFOTg7effddHDp0CIaGhhU+BxMVIiIieiOdO3eGIAgv3S+TybBgwQIsWLDgjc/BRIWIiEgCpPpZP0xUiIiIJEALS1Q0gnf9EBERkWixokJERCQFEi2pMFEhIiKSAG3c9aMJnPohIiIi0WJFhYiISAJ41w8RERGJlkSXqDBRISIikgSJZipco0JERESixYoKERGRBEj1rh8mKkRERFKghsW0IsxTOPVDRERE4sVEhdRu3Y7j8Og3F7btJ8Fn+DLE/X5L2yFJHq+5ZvF6a8bEfk2RtW0EQoa1Lnf/9qDuyNo2Ar1bOmg4MnGSqWkTGyYqpFa7f47D7JV7EDSqF45tDkITl7oYND4U97Ifajs0yeI11yxeb81o4VQL/t3ccPWv7HL3f9rLHYKg4aDETqKZilYTleHDh0Mmk0Emk8HAwADOzs5YsGABnj59qrbxBwwYoJaxqGLWbP0Vwwa0g18/bzR0qoOvZn4AY0MDfL/3jLZDkyxec83i9a56JnI9rB3XEZPXxSDnUWGZ/U0cayKgTxNM+PaUFqIjTdN6RaVnz55IT0/HjRs3MHXqVMyfPx/Lli3Tdlj0BoqKn+LStVR0bu2maNPR0UGn1m6IvZKsxciki9dcs3i9NWPpf7xx5LfbOH41vcw+IwNd/HdcJ0wPP4vM3CdaiE68ZGr6T2y0nqjI5XLY2trC0dERn332GXx8fLB3714UFhYiMDAQdevWhYmJCdq0aYNjx44pjouIiIClpSUOHz6MRo0awdTUVJH0AMD8+fOxceNG/Pjjj4qqzfPjg4KC4OrqCmNjYzg5OWHOnDkoLi5WimvhwoWwtraGmZkZRo0ahRkzZqB58+aK/aWlpViwYAHq1asHuVyO5s2b49ChQ4r9t27dgkwmw+7du9GlSxcYGxujWbNmOHNGun91ZeXko6SkFLVrmim1165pjsysPC1FJW285prF6131/uXdAB71rfB5ZFy5+xd+3Abnr2fip7gUDUcmfs8foV/ZTWy0nqj8k5GREYqKijBu3DicOXMGkZGRuHz5MgYPHoyePXvixo0bir6PHz/Gl19+ic2bN+PEiRNISUlBYGAgACAwMBBDhgxRJC/p6elo164dAMDMzAwRERH4448/sGrVKqxbtw4rVqxQjLtlyxaEhIRgyZIliIuLg4ODA8LCwpTiXLVqFZYvX44vv/wSly9fhq+vL/r166cUHwDMmjULgYGBuHTpElxdXTF06NBXTm0VFhYiLy9PaSMiqg7sappgkX8bfBJ6HIXFJWX29/SyR4fGdTBr0zktREfaIprnqAiCgOjoaBw+fBhDhw5FeHg4UlJSYGdnB+BZ4nHo0CGEh4dj0aJFAIDi4mKsXbsW77zzDgBg3LhxWLBgAQDA1NQURkZGKCwshK2trdK5Zs+erfi6fv36CAwMRGRkJKZPnw4A+PrrrzFy5EiMGDECADB37lz8/PPPyM/PVxz35ZdfIigoCB988AEAYMmSJTh69ChWrlyJ0NBQRb/AwED06dMHABAcHIzGjRvj5s2baNiwYbnXYfHixQgODn7Dq6hdVpam0NXVKbOo8F52HqytzLUUlbTxmmsWr3fVau5kBWsLIxxd1E/Rpqerg3YNbTGqRyOE/3INDWzM8OcGP6XjIiZ3wZlrGej/+aF/DlmtSPQJ+tpPVPbv3w9TU1MUFxejtLQUH374Id5//31ERETA1dVVqW9hYSGsrKwUr42NjRVJCgDUqVMHmZmZrz3n9u3bsXr1aiQlJSE/Px9Pnz6Fufn/fsgkJiZi7NixSse0bt0av/76KwAgLy8PaWlpaN++vVKf9u3bIz4+XqnNw8NDKT4AyMzMfGmiMnPmTEyZMkXxOi8vD/b29q99T2JgoK+H5g3tcTw2EX06NwPwbIrsROx1jBrcUcvRSROvuWbxeletE1fT0H7aHqW2bz59FzfScrFq7xVkPyxExC+JSvtjlv0Lszedx6GLqZoMVZwkmqloPVHp0qULwsLCYGBgADs7O+jp6WH79u3Q1dVFXFwcdHV1lfqbmpoqvtbX11faJ5PJILzmfrUzZ87Az88PwcHB8PX1hYWFBSIjI7F8+XL1vakXvBij7O/Jv9LS0pf2l8vlkMvlVRKLJoz9sCvGBm9Gi0YO8GxcH2HbjuLRk0L49W2r7dAki9dcs3i9q05+wVNcu52j1Pao8Cmy8wsV7eUtoL2d9Qgp9/LLtFc3fIR+FTExMYGzs7NSW4sWLVBSUoLMzEx06NDhjcc2MDBASYnyPOfp06fh6OiIWbNmKdr++usvpT5ubm6IjY3FsGHDFG2xsbGKr83NzWFnZ4eYmBh06tRJ0R4TE4PWrct/MFF1MbCHF+7n5GPRtweQmfUQTV3rYufqAJbFqxCvuWbxehNpltYTlfK4urrCz88Pw4YNw/Lly9GiRQvcu3cP0dHR8PDwUKz5eJ369evj8OHDSExMhJWVFSwsLODi4oKUlBRERkaiVatWOHDgAPbsUS41jh8/HqNHj0bLli3Rrl07bN++HZcvX4aTk5Oiz7Rp0zBv3jy88847aN68OcLDw3Hp0iVs2bJFrdfibTRmSCeMGdLp9R1JbXjNNYvXW3Net+7Eami4hiIRPxkqf9eO+OopIk1UACA8PBwLFy7E1KlTcefOHdSqVQtt27bFe++9V+ExRo8ejWPHjqFly5bIz8/H0aNH0a9fP0yePBnjxo1DYWEh+vTpgzlz5mD+/PmK4/z8/PDnn38iMDAQBQUFGDJkCIYPH47z588r+kyYMAG5ubmYOnUqMjMz4e7ujr1798LFxUWdl4GIiKhCJLpEBTLhdYs6CADQvXt32NraYvPmzRo9b15eHiwsLJCRlau04JeI6E2xCqE5QvETPPkxALm5Vfcz/Pnvid+TM2FWyXM8zMtD4wbWVRqvqkRbUdGmx48fY+3atfD19YWuri62bduGX375BUeOHNF2aEREROVSxwPbxPjANyYq5ZDJZDh48CBCQkJQUFAANzc37Nq1Cz4+PtoOjYiI6CWkOfnDRKUcRkZG+OWXX7QdBhERUbXHRIWIiEgCOPVDREREoiXNiR8RfighERER0XOsqBAREUkAp36IiIhItPhZP0RERCReEl2kwjUqREREJFqsqBAREUmARAsqTFSIiIikQKqLaTn1Q0RERKLFigoREZEE8K4fIiIiEi+JLlLh1A8RERGJFisqREREEiDRggoTFSIiIingXT9EREREGsaKChERkSRU/q4fMU7+MFEhIiKSAE79EBEREWkYExUiIiISLU79EBERSYBUp36YqBAREUmAVB+hz6kfIiIiEi1WVIiIiCSAUz9EREQkWlJ9hD6nfoiIiEi0WFEhIiKSAomWVJioEBERSQDv+iEiIiLSMFZUiIiIJIB3/RAREZFoSXSJChMVIiIiSZBopsI1KkRERPTGQkNDUb9+fRgaGqJNmzY4f/68WsdnokJERCQBMjX9p4rt27djypQpmDdvHi5evIhmzZrB19cXmZmZantfTFSIiIgk4Pli2spuqvjqq68wevRojBgxAu7u7li7di2MjY3x3Xffqe19cY2KyAmCAAB4mJen5UiISCqE4ifaDqHaeH6tn/8sr0p5avg98XyMf44ll8shl8uV2oqKihAXF4eZM2cq2nR0dODj44MzZ85UOpbnmKiI3MOHDwEAzg3stRwJERG9qYcPH8LCwqJKxjYwMICtrS1c1PR7wtTUFPb2ymPNmzcP8+fPV2q7f/8+SkpKYGNjo9RuY2ODa9euqSUWgImK6NnZ2SE1NRVmZmaQifEG95fIy8uDvb09UlNTYW5uru1wJI/XW/N4zTXrbb3egiDg4cOHsLOzq7JzGBoaIjk5GUVFRWoZTxCEMr9v/llN0SQmKiKno6ODevXqaTuMN2Zubv5W/VB52/F6ax6vuWa9jde7qiopLzI0NIShoWGVn+dFtWrVgq6uLjIyMpTaMzIyYGtrq7bzcDEtERERqczAwABeXl6Ijo5WtJWWliI6Ohre3t5qOw8rKkRERPRGpkyZAn9/f7Rs2RKtW7fGypUr8ejRI4wYMUJt52CiQlVCLpdj3rx5Wp3XrE54vTWP11yzeL3F6d///jfu3buHuXPn4u7du2jevDkOHTpUZoFtZcgETdwzRURERPQGuEaFiIiIRIuJChEREYkWExUiIiISLSYq9EZkMhmioqK0PgZRZc2fPx/NmzfX+HkjIiJgaWmp8fMSvW2YqFC57t69i/Hjx8PJyQlyuRz29vbo27ev4n759PR09OrVS8tRvp3u3buHzz77DA4ODpDL5bC1tYWvry9iYmK0HdpbTyaTvXL75yPAASAwMFDpORD0asOHD1dcTwMDAzg7O2PBggV4+vSp2sYfMGCAWsYiaeDtyVTGrVu30L59e1haWmLZsmVo2rQpiouLcfjwYQQEBODatWuvfepgcXEx9PX1NRTx22XQoEEoKirCxo0b4eTkhIyMDERHRyMrK0urcRUVFcHAwECrMVRWenq64uvt27dj7ty5SExMVLSZmpoqvhYEASUlJTA1NVVqp9fr2bMnwsPDUVhYiIMHDyIgIAD6+vpKH05HpDYC0T/06tVLqFu3rpCfn19m34MHDwRBEAQAwp49ewRBEITk5GQBgBAZGSl07NhRkMvlQnh4uCAIgrBhwwbB3d1dMDAwEGxtbYWAgADFWC+OIQiCkJKSIgwePFiwsLAQatSoIfTr109ITk6uonepHQ8ePBAACMeOHXtpn+vXrwsdOnQQ5HK50KhRI+Hnn39WulZHjx4VACi+F4IgCL/99psAQHG97t+/L3zwwQeCnZ2dYGRkJDRp0kTYunWr0nk6deokBAQECBMnThSsrKyEzp07C4IgCFeuXBF69uwpmJiYCNbW1sJHH30k3Lt3T63XQRPCw8MFCwsLxevn1+3gwYOCp6enoK+vLxw9elSYN2+e0KxZM0W/8+fPCz4+PoKVlZVgbm4udOzYUYiLi1MaG4Cwbt06YcCAAYKRkZHg7Ows/Pjjj0p9fvzxR8HZ2VmQy+VC586dhYiICKXv2z/jEwRBiIqKElq0aCHI5XKhQYMGwvz584Xi4mJ1XpZK8/f3F/r376/U1r17d6Ft27ZCQUGBMHXqVMHOzk4wNjYWWrduLRw9elTR7/l7PnTokNCwYUPBxMRE8PX1FdLS0gRBEIR58+YJAJS258dPnz5dcHFxEYyMjIQGDRoIs2fPFoqKipTi+Pzzz4XatWsLpqamwsiRI4WgoCCl721JSYkQHBws1K1bVzAwMBCaNWsm/PTTT4r9z3+W7dq1S+jcubNgZGQkeHh4CKdPn1brNSTVcOqHlGRnZ+PQoUMICAiAiYlJmf2vmlOfMWMGJk6ciISEBPj6+iIsLAwBAQEYM2YMrly5gr1798LZ2bncY4uLi+Hr6wszMzOcPHkSMTExMDU1Rc+ePdX2QVti8Pyv96ioKBQWFpbZX1paioEDB8LAwADnzp3D2rVrERQUpPJ5CgoK4OXlhQMHDuDq1asYM2YMPv74Y5w/f16p38aNG2FgYICYmBisXbsWOTk56Nq1K1q0aIELFy7g0KFDyMjIwJAhQ974PYvNjBkz8MUXXyAhIQEeHh5l9j98+BD+/v44deoUzp49CxcXF/Tu3VvxSebPBQcHY8iQIbh8+TJ69+4NPz8/ZGdnAwCSk5Px/vvvY8CAAYiPj8cnn3yCWbNmvTKukydPYtiwYZg4cSL++OMPfPvtt4iIiEBISIj63nwVMTIyQlFREcaNG4czZ84gMjISly9fxuDBg9GzZ0/cuHFD0ffx48f48ssvsXnzZpw4cQIpKSkIDAwE8GwabsiQIejZsyfS09ORnp6Odu3aAQDMzMwQERGBP/74A6tWrcK6deuwYsUKxbhbtmxBSEgIlixZgri4ODg4OCAsLEwpzlWrVmH58uX48ssvcfnyZfj6+qJfv35K8QHArFmzEBgYiEuXLsHV1RVDhw5V29QWvQFtZ0okLufOnRMACLt3735lP5RTUVm5cqVSHzs7O2HWrFkVGmPz5s2Cm5ubUFpaqthfWFgoGBkZCYcPH36zNyNSO3fuFGrUqCEYGhoK7dq1E2bOnCnEx8cLgiAIhw8fFvT09IQ7d+4o+v/0008qV1TK06dPH2Hq1KmK1506dRJatGih1Ofzzz8XevToodSWmpoqABASExPf8B1rx8sqKlFRUUr9/llR+aeSkhLBzMxM2Ldvn6INgDB79mzF6/z8fAGA4q/zoKAgoUmTJkrjzJo165UVlW7dugmLFi1SOmbz5s1CnTp1KvJ2NebFikppaalw5MgRQS6XC8OHDxd0dXWV/u0KwrP3NXPmTEEQnr1nAMLNmzcV+0NDQwUbG5tyx3+VZcuWCV5eXorXbdq0UarYCoIgtG/fXul7a2dnJ4SEhCj1adWqlTB27FhBEP73s2z9+vWK/b///rsAQEhISHhtTFQ1uEaFlAiVeFBxy5YtFV9nZmYiLS0N3bp1q9Cx8fHxuHnzJszMzJTaCwoKkJSU9MYxidGgQYPQp08fnDx5EmfPnsVPP/2EpUuXYv369cjNzYW9vb3SR8K/yYd7lZSUYNGiRdixYwfu3LmDoqIiFBYWwtjYWKmfl5eX0uv4+HgcPXq03DUbSUlJcHV1VTkWsXnx32l5MjIyMHv2bBw7dgyZmZkoKSnB48ePkZKSotTvxWqMiYkJzM3NkZmZCQBITExEq1atlPq3bt36leeNj49HTEyMUgWlpKQEBQUFePz4cZnvnTbt378fpqamKC4uRmlpKT788EO8//77iIiIKPNvpLCwEFZWVorXxsbGeOeddxSv69Spo7hur7J9+3asXr0aSUlJyM/Px9OnT5U+RTkxMRFjx45VOqZ169b49ddfAQB5eXlIS0tD+/btlfq0b98e8fHxSm0vfm/r1KkD4NnPtIYNG742TlI/JiqkxMXFBTKZDNeuXVP52BenioyMjFQ6Nj8/H15eXtiyZUuZfbVr11Y5FrEzNDRE9+7d0b17d8yZMwejRo3CvHnzMGXKlNceq6PzbMb2xaSyuLhYqc+yZcuwatUqrFy5Ek2bNoWJiQkmTZpUZhrtn9N7+fn56Nu3L5YsWVLmvM9/YL/typvSfJG/vz+ysrKwatUqODo6Qi6Xw9vbu8y1++dicZlMhtLS0jeOKz8/H8HBwRg4cGCZfYaGhm88blXo0qULwsLCYGBgADs7O+jp6WH79u3Q1dVFXFwcdHV1lfq/mPiWd91e9wfSmTNn4Ofnh+DgYPj6+sLCwgKRkZFYvny5+t7UC16MUSaTAUClvrdUOUxUSEnNmjXh6+uL0NBQTJgwocwP9ZycnAo9+8HMzAz169dHdHQ0unTp8tr+np6e2L59O6ytrZX+Sqou3N3dERUVhUaNGiE1NRXp6emKxODs2bNKfZ8nbunp6ahRowYA4NKlS0p9YmJi0L9/f3z00UcAnv2QvX79Otzd3V8Zh6enJ3bt2oX69etDT696/niIiYnBmjVr0Lt3bwBAamoq7t+/r9IYbm5uOHjwoFJbbGzsK4/x9PREYmLiS9dxiYmJiUmZOFu0aIGSkhJkZmaiQ4cObzy2gYEBSkpKlNpOnz4NR0dHpXU+f/31l1IfNzc3xMbGYtiwYYq2F6+5ubk57OzsEBMTg06dOinaY2JiXlvtIu3iYloqIzQ0FCUlJWjdujV27dqFGzduICEhAatXr1ZpGmL+/PlYvnw5Vq9ejRs3buDixYv4+uuvy+3r5+eHWrVqoX///jh58iSSk5Nx7NgxTJgwAbdv31bXW9O6rKwsdO3aFd9//z0uX76M5ORk/PDDD1i6dCn69+8PHx8fuLq6wt/fH/Hx8Th58mSZRZjOzs6wt7fH/PnzcePGDRw4cKDMX5YuLi44cuQITp8+jYSEBHzyySfIyMh4bXwBAQHIzs7G0KFDERsbi6SkJBw+fBgjRowo88tDqlxcXLB582YkJCTg3Llz8PPzU7lC+Mknn+DatWsICgrC9evXsWPHDkRERAD431/o/zR37lxs2rQJwcHB+P3335GQkIDIyEjMnj27sm9JI1xdXeHn54dhw4Zh9+7dSE5Oxvnz57F48WIcOHCgwuPUr18fly9fRmJiIu7fv4/i4mK4uLggJSUFkZGRSEpKwurVq7Fnzx6l48aPH48NGzZg48aNuHHjBhYuXIjLly8rXe9p06ZhyZIl2L59OxITEzFjxgxcunQJEydOVNt1IPVjokJlODk54eLFi+jSpQumTp2KJk2aoHv37oiOji6ziv5V/P39sXLlSqxZswaNGzfGe++9V2Z1/XPGxsY4ceIEHBwcMHDgQDRq1AgjR45EQUGBpCospqamaNOmDVasWIGOHTuiSZMmmDNnDkaPHo1vvvkGOjo62LNnD548eYLWrVtj1KhRZe760NfXx7Zt23Dt2jV4eHhgyZIlWLhwoVKf2bNnw9PTE76+vujcuTNsbW0r9BCt539xlpSUoEePHmjatCkmTZoES0tLxZST1G3YsAEPHjyAp6cnPv74Y0yYMAHW1tYqjdGgQQPs3LkTu3fvhoeHB8LCwhQJp1wuL/cYX19f7N+/Hz///DNatWqFtm3bYsWKFXB0dKz0e9KU8PBwDBs2DFOnToWbmxsGDBiA2NhYODg4VHiM0aNHw83NDS1btkTt2rURExODfv36YfLkyRg3bhyaN2+O06dPY86cOUrH+fn5YebMmQgMDISnpyeSk5MxfPhwpWmzCRMmYMqUKZg6dSqaNm2KQ4cOYe/evXBxcVHbNSD1kwmVWT1JRBohk8mwZ88ePrHzLRYSEoK1a9ciNTVV26FUG927d4etrS02b96s7VCoEqrnJDQRURVbs2YNWrVqBSsrK8TExGDZsmUYN26ctsOSrMePH2Pt2rXw9fWFrq4utm3bhl9++QVHjhzRdmhUSUxUiIiqwPN1EtnZ2XBwcMDUqVP5iPkqJJPJcPDgQYSEhKCgoABubm7YtWsXfHx8tB0aVRKnfoiIiEi0qsfqOCIiInorMVEhIiIi0WKiQkRERKLFRIWIiIhEi4kKERERiRYTFSJ6reHDhys9bK5z586YNGmSxuM4duwYZDIZcnJyXtpHJpMhKiqqwmPOnz8fzZs3r1Rct27dgkwmK/OZS0RUeUxUiN5Sw4cPh0wmg0wmg4GBAZydnbFgwQI8ffq0ys+9e/dufP755xXqW5HkgojoZfjAN6K3WM+ePREeHo7CwkIcPHgQAQEB0NfXL/fBYkVFRTAwMFDLeWvWrKmWcYiIXocVFaK3mFwuh62tLRwdHfHZZ5/Bx8cHe/fuBfC/6ZqQkBDY2dnBzc0NAJCamoohQ4bA0tISNWvWRP/+/XHr1i3FmCUlJZgyZQosLS1hZWWF6dOn45/Phfzn1E9hYSGCgoJgb28PuVwOZ2dnbNiwAbdu3UKXLl0AADVq1IBMJsPw4cMBAKWlpVi8eDEaNGgAIyMjNGvWDDt37lQ6z8GDB+Hq6gojIyN06dJFKc6KCgoKgqurK4yNjeHk5IQ5c+aguLi4TL9vv/0W9vb2MDY2xpAhQ5Cbm6u0f/369WjUqBEMDQ3RsGFDrFmzRuVYiEh1TFSIJMTIyAhFRUWK19HR0UhMTMSRI0ewf/9+FBcXw9fXF2ZmZjh58iRiYmJgamqKnj17Ko5bvnw5IiIi8N133+HUqVPIzs7Gnj17XnneYcOGYdu2bVi9ejUSEhLw7bffwtTUFPb29ti1axcAIDExEenp6Vi1ahUAYPHixdi0aRPWrl2L33//HZMnT8ZHH32E48ePA3iWUA0cOBB9+/bFpUuXMGrUKMyYMUPla2JmZoaIiAj88ccfWLVqFdatW4cVK1Yo9bl58yZ27NiBffv24dChQ/jtt98wduxYxf4tW7Zg7ty5CAkJQUJCAhYtWoQ5c+Zg48aNKsdDRCoSiOit5O/vL/Tv318QBEEoLS0Vjhw5IsjlciEwMFCx38bGRigsLFQcs3nzZsHNzU0oLS1VtBUWFgpGRkbC4cOHBUEQhDp16ghLly5V7C8uLhbq1aunOJcgCEKnTp2EiRMnCoIgCImJiQIA4ciRI+XGefToUQGA8ODBA0VbQUGBYGxsLJw+fVqp78iRI4WhQ4cKgiAIM2fOFNzd3ZX2BwUFlRnrnwAIe/bseen+ZcuWCV5eXorX8+bNE3R1dYXbt28r2n766SdBR0dHSE9PFwRBEN555x1h69atSuN8/vnngre3tyAIgpCcnCwAEH777beXnpeI3gzXqBC9xfbv3w9TU1MUFxejtLQUH374IebPn6/Y37RpU6V1KfHx8bh58ybMzMyUxikoKEBSUhJyc3ORnp6ONm3aKPbp6emhZcuWZaZ/nrt06RJ0dXXRqVOnCsd98+ZNPH78GN27d1dqLyoqQosWLQAACQkJSnEAgLe3d4XP8dz27duxevVqJCUlIT8/H0+fPoW5ublSHwcHB9StW1fpPKWlpUhMTISZmRmSkpIwcuRIjB49WtHn6dOnsLCwUDkeIlINExWit1iXLl0QFhYGAwMD2NnZQU9P+X9pExMTpdf5+fnw8vLCli1byoxVu3btN4rByMhI5WPy8/MBAAcOHFBKEIBn627U5cyZM/Dz80NwcDB8fX1hYWGByMhILF++XOVY161bVyZx0tXVVVusRFQ+JipEbzETExM4OztXuL+npye2b98Oa2vrMlWF5+rUqYNz586hY8eOAJ5VDuLi4uDp6Vlu/6ZNm6K0tBTHjx+Hj49Pmf3PKzolJSWKNnd3d8jlcqSkpLy0EtOoUSPFwuDnzp49+/o3+YLTp0/D0dERs2bNUrT99ddfZfqlpKQgLS0NdnZ2ivPo6OjAzc0NNjY2sLOzw59//gk/Pz+Vzk9ElcfFtETViJ+fH2rVqoX+/fvj5MmTSE5OxrFjxzBhwgTcvn0bADBx4kR88cUXiIqKwrVr1zB27NhXPgOlfv368Pf3x3/+8x9ERUUpxtyxYwcAwNHRETKZDPv378e9e/eQn58PMzMzBAYGYvLkydi4cSOSkpJw8eJFfP3114oFqp9++ilu3LiBadOmITExEVu3bkVERIRK79fFxQUpKSmIjIxEUlISVq9eXe7CYENDQ/j7+yM+Ph4nT57EhAkTMGTIENja2gIAgoODsXjxYqxevRrXr1/HlStXEB4ejq+++kqleIhIdUxUiKoRY2NjnDhxAg4ODhg4cCAaNWqEkSNHoqCgQFFhmTp1Kj7++GP4+/vD29sbZmZm+Ne//vXKccPCwvD+++9j7NixaNiwIUaPHo1Hjx4BAOrWrYvg4GDMmDEDNjY2GDduHADg888/x5w5c7B48WI0atQIPXv2xIEDB9CgQQMAz9aN7Nq1C1FRUWjWrBnWrl2LRYsWqfR++/Xrh8mTJ2PcuHFo3rw5Tp8+jTlz5pTp5+zsjIEDB6J3797o0aMHPDw8lG4/HjVqFNavX4/w8HA0bdoUnTp1QkREhCJWIqo6MuFlK+SIiIiItIwVFSIiIhItJipEREQkWkxUiIiISLSYqBAREZFoMVEhIiIi0WKiQkRERKLFRIWIiIhEi4kKERERiRYTFSIiIhItJipEREQkWkxUiIiISLT+H/GLlpXNdTcUAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\"save_model_weights(model1, 'model1_weights.pth')\\nsave_model_weights(model2, 'model2_weights.pth')\\nsave_model_weights(model3, 'model3_weights.pth')\\nsave_model_weights(model_fusion, 'model_fusion_weights.pth')\""
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_confusion_matrix(true_labels, predictions, classes):\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.show()\n",
        "\n",
        "def save_model_weights(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "# Extract true labels from test_loader_fused\n",
        "true_labels = []\n",
        "for _, labels in test_loader_fused:\n",
        "    true_labels.extend(labels.numpy())\n",
        "\n",
        "# Perform majority voting and store the predictions\n",
        "accuracy_majority_voting_fusion, predictions_all = majority_voting(models, test_loader_fused) # Assign output of majority_voting to predictions_all\n",
        "\n",
        "# Define class labels (replace with your actual class labels)\n",
        "class_labels = ['Circle', 'Square', 'Triangle', 'Pentagon'] # Define class_labels\n",
        "\n",
        "\n",
        "# Plot confusion matrix for majority voting fusion model\n",
        "plot_confusion_matrix(true_labels, predictions_all, class_labels)\n",
        "\n",
        "# Save model weights\n",
        "\"\"\"save_model_weights(model1, 'model1_weights.pth')\n",
        "save_model_weights(model2, 'model2_weights.pth')\n",
        "save_model_weights(model3, 'model3_weights.pth')\n",
        "save_model_weights(model_fusion, 'model_fusion_weights.pth')\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
